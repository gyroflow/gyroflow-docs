{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Gyroflow Docs!","text":"<p>Return to gyroflow.xyz</p> <p>Here you can find information about setup and configuration of the Gyroflow stabilization software.</p>"},{"location":"#what-is-gyroflow","title":"What is Gyroflow?","text":"<p>In order to achieve smooth, cinematic footage, video stabilization is often essential. For cinema cameras, this is often achieved using motorized gimbals or other bulky camera stabilizers. Phone cameras and compact action cameras on the other hand use Electronic Image Stabilization (EIS) applied in real-time based on gyro sensor data. Finally, video editing packages can often stabilize video based on estimated camera motion, which may be unreliable.</p> <p>This is where Gyroflow comes into play. Gyroflow is a post-processing video stabilization software based on logged motion data. With the help of precise lens calibrations, rolling shutter correction, and tweakable stabilization algorithms (including horizon levelling), Gyroflow can produce gimbal-like stabilization with no or minimal weight penalty. It also works regardless of lighting conditions or moving subjects. This is especially suited for aerial videography, where the beta version has been extensively evaluated for large and small productions alike. With many cameras from GoPro, Sony, insta360 etc. supporting built-in motion data recording, additional hardware might not even be required. You can even use a GoPro as a logger for a cinema camera.</p> <p>Gyroflow is cross-platform (even supports Apple Silicon), and uses hardware acceleration for blazingly fast processing combined with a modern multilingual user interface.</p>"},{"location":"faq/","title":"FAQ","text":"<p>TBA</p>"},{"location":"cams/blackmagic/","title":"Blackmagic","text":"<p>Blackmagic Pocket 4K/6K cameras recently got a firmware update in order to enable gyro metadata logging (Camera firmware 7.9). Furthermore, the latest Resolve 18 beta release has added a feature to apply gyro-based stabilization. The latest development builds of Gyroflow allow the use of BRAW with this metadata.</p> <p>Furthermore, Gyroflow also allows playback and analysis of BRAW footage directly, which streamlines the workflow compared to analysing a proxy. Note that Gyroflow doesn't allow rendering this footage. Instead the recommended workflow uses the OpenFX plugin in combination with Gyroflow for lossless image stabilization. </p>"},{"location":"cams/dji/","title":"DJI","text":"<p>In collaboration with DJI we created a Gyroflow compatible way to store motion data and more camera information for the stabilization process inside  video files. To make the experience in Gyroflow as easy and reliable as possible, the video contains the factory lens profile and frame based motion data. After loading a video, the stabilized preview is ready to export and no sync-points are needed.</p>"},{"location":"cams/dji/#general","title":"General","text":"<p>In order to record open gyro data for Gyroflow , DJI products use the same concept. The internal image stabilization (EIS), Rocksteady must be disabled and the WIDE lens profile needs to be selected. </p>"},{"location":"cams/dji/#dji-avata","title":"DJI Avata","text":"<p>The Avata was the first collaboration with the development team at DJI, and it is the first product from DJI with Gyroflow support out of the box. </p> <p>To record for Gyroflow:</p> <pre><code>- EIS disabled\n- WIDE lens profile\n- 4K and 2.7K  4:3\n- 4K and 2.7K  16:9\n</code></pre>"},{"location":"cams/dji/#dji-o3-airunit","title":"DJI O3 AirUnit","text":"<p>DJI surprised us with the O3 Airunit and the idea of combining a digital-HD FPV stack and an Actioncam with Gyroflow support in one unit. The hardware is similar to the Action 2 and allows improving the FPV experience for \"homemade\" DIY drones and all sorts of FPV platforms. Like the Avata, the O3 Airunit can record motion data :</p> <p>To record for Gyroflow:</p> <pre><code>- EIS disabled\n- WIDE lens profile\n- 4K and 2.7K  4:3\n- 4K and 2.7K  16:9\n</code></pre> <p>To use the O3 EIS/Rocksteady and in order to record for Gyroflow on drones, it's often necessary to isolate the motion sensor inside the camera module  from vibrations. Stiff carbon camera plates and ALU camera cages allow vibrations to travel to the camera and to influence the IMU. It's recommended to isolate the camera using a 3D printed TPU mount to fix the issue in most cases.  RPM filters in Betaflight should be configured correctly in order to get the best Gyroflow performance and image quality. For certain drone and prop sizes, it's necessary to set the ESC PWM control frequency to 48 kHz or higher. </p>"},{"location":"cams/dji/#dji-action-2-closed-beta-v-010404100","title":"DJI Action 2 - closed BETA (V 01.04.04100)","text":"<p>Finally, the Action 2 get's it well deserved Gyroflow support and a group of Testers, selected by DJI after registration, is currently testing  a beta firmware. The experience so far is very positive and we identified a few bugs that will be addressed in the next firmware.</p> <p>To record for Gyroflow:</p> <pre><code> - EIS disabled\n - WIDE lens profile\n - 4K 4:3   24-60 fps\n - 4K 16:9  100/120 fps\n\n Not working ( V 01.04.04100 bug )\n - 4K 4:3 50\n</code></pre>"},{"location":"cams/dji/#using-dji-open-gyro-data-to-stabilize-a-different-camera","title":"Using DJI open gyro data to stabilize a different camera:","text":"<p>DJI doesn't record RAW IMU data, only Quaternions - \"frame based motion data\" useable to stabilize other cameras. It's necessary to sync the external video source and the motion data provided by Action 2 or O3 Airunit. </p> <pre><code>- Use the Integration method: None\n- Right click on timeline -&gt; View mode: Quaternions\n- Make sure to set large enough Sync search size\n</code></pre>"},{"location":"cams/general/","title":"General","text":"<p>Welcome to Camera and Gyro Logging Guide!</p> <p>This page contains some useful information about camera settings and supported gyro data formats. For more details, please refer to the left navigation bar.</p>"},{"location":"cams/general/#camera-recording-tips","title":"Camera Recording Tips","text":"<ul> <li>Use the settings that give the widest possible field of view. This results in more data to work with. For a lot of cameras, this is using the 4:3 aspect ratio if available.</li> <li>If using the main flight controller on a drone for logging, the camera should be rigidly mounted to the drone.</li> <li>If using a secondary logger on the camera or internal camera logging, some soft mounting is preferred when used in a high-vibration environment (drones).</li> <li>Internal stabilization should be disabled. Furthermore, trying to stabilize footage from a camera with IBIS may result in wobble due to the sensor shifting around.</li> <li>A 90 degree shutter is typically a good compromise between artifacts and pleasing motion blur, and is thus a good starting point. In filmmaking, the 180 degree shutter rule is commonly used (shutter speed half of framerate). Depending on your use case and amount of shake, applying Gyroflow stabilization may result in undesired motion blur artifacts. Note that even higher shutter speeds can make the footage look less \"cinematic\" due to the lack of motion blur. If you're only concerned about stabilization, a higher shutter speed is generally better.</li> </ul>"},{"location":"cams/general/#supported-gyro-formats","title":"Supported gyro formats","text":"<p>Gyroflow needs a source of gyroscope data (and optionally accelerometer data) to operate. Currently, Gyroflow supports the following gyro log types:</p> <ul> <li>GoPro (All models with gyro metadata, starting with HERO 5)</li> <li>Sony (a1, a7c, a7r IV, a7 IV, a7s III, a9 II, FX3, FX6, RX0 II, RX100 VII, ZV1, ZV-E10)</li> <li>Insta360 (OneR, SMO 4k, GO2)</li> <li>DJI (Avata, O3 Airunit, ...)</li> <li>Betaflight blackbox (CSV and binary)</li> <li>Runcam CSV (Runcam 5 Orange, iFlight GOCam GR)</li> <li>Hawkeye Firefly X Lite CSV</li> <li>WitMotion (WT901SDCL binary and *.txt - devices unreliable)</li> <li>Mobile apps: <code>Sensor Logger</code>, <code>G-Field Recorder</code>, <code>Gyro</code></li> <li>Gyroflow .gcsv log</li> <li>ArduPilot VideoStabilization logging (*.log)</li> <li>(TODO) DJI flight logs (.dat, .txt)</li> </ul>"},{"location":"cams/gopro/","title":"GoPro","text":"<p>From the GoPro Hero 5 and onwards, the GPMF metadata has contained useful motion data supported by Gyroflow. Unfortunately not all cameras work equally well:</p>"},{"location":"cams/gopro/#general","title":"General","text":"<p>All GoPros use 4:3 sensors and allow for different field of views. For Gyroflow stabilization, the best resolutions are 4:3 resolutions with the <code>wide</code> field of view. This gives Gyroflow the most image data to work with.</p> <p>By default, GoPro files are limited to 4 GB in size. For longer files, use either the GoPro Labs large chapter support, or use ReelSteady-Joiner to join segmented files together.</p>"},{"location":"cams/gopro/#hero-8910","title":"Hero 8/9/10","text":"<p>These cameras all contain pre-computed camera orientations for every single frame, meaning the synchronisation step can be skipped when using the <code>None</code> integration method. Footage from these cameras are essentially \"plug and play\" when it comes to Gyroflow stabilization, since Gyroflow contains built-in lens profiles for all these cameras. Furthermore, since these cameras do internal rolling shutter processing, additional rolling shutter correction is not required.</p> <p>Finally, the GPMF metadata also contains transformed orientation information when hypersmooth is enabled, meaning further stabilization of hypersmoothed footage in Gyroflow is possible.</p>"},{"location":"cams/gopro/#hero-7","title":"Hero 7","text":"<p>The Hero 7 is a bit of an outlier. For drone footage, the gyro data from the Hero 7 have been found to be lackluster to say the least. High amounts of noise and aliasing means Gyroflow stabilization using the internal data is likely to give bad results. For this reason, the Hero 7 is not recommended for cinematic FPV footage. One workaround is to use external gyro logging, for instance using the drone blackbox. Another workaround is the use of vibration-dampening mount, which can be a hassle compared to other GoPros.</p> <p>Some users have reported that using intense low pass filtering of the gyro data (e.g. cutoff of 4 Hz or less) can yield acceptable results for some drone footage. This cannot correct for e.g. higher frequency propwash oscillations or vibrations, but can smooth out the general movement. </p> <p>The Hero 7 doesn't compute per-frame orientations, meaning synchronization is required. For handheld footage, the mentioned noise issues shouldn't be a problem. Furthermore, footage from the Hero 7 with Hypersmooth enabled does not work with Gyroflow.</p>"},{"location":"cams/gopro/#hero-6","title":"Hero 6","text":"<p>The Hero 6 contains gyroscope and accelerometer data, and can thus be used with Gyroflow out of the box. Due to the lack of per-frame orientations, the synchronization step is still required. The Hero 6 doesn't exhibit the noise issues of the Hero 7, and works well for drone footage. Compared to Hero 8/9/10, no internal rolling shutter processing is performed, meaning fast motion can cause warping, if no rolling shutter correction is applied in Gyroflow.</p>"},{"location":"cams/gopro/#hero-5session-5","title":"Hero 5/Session 5","text":"<p>The Hero 5 exhibits similar vibration-induced noise problems to the Hero 7, and is thus not recommended for drone footage out of the box. Once again, users have reported achieving acceptable stabilization using intense low pass filtering, so if you already have this camera, that's worth a try. Just like the Hero 7, handheld footage doesn't yield any major problems. </p>"},{"location":"cams/insta360/","title":"Insta360","text":"<p>Action cameras from Insta360 (OneR, SMO 4k, Go, GO2) support gyro logging for use with the Flowstate stabilization option. This metadata also works with Gyroflow. Once again, try recording at the widest possible field of view. e.g. the Pro Video on the Go 2 saves the full sensor frame.</p>"},{"location":"cams/mobius/","title":"Mobius","text":""},{"location":"cams/mobius/#mobius-maxi-4k","title":"Mobius Maxi 4K","text":"<p>With the latest available firmware, this camera logs gyro data using the .gcsv format and can be used with Gyroflow.</p>"},{"location":"cams/red/","title":"RED Cinema","text":"<p>Warning</p> <p>While most RED cameras have the required hardware for gyro logging, not all of them have this feature enabled.</p>  <p>Some cameras from RED cinema save motion data, either on a per-frame basis, or asynchronously (faster sample rate). This data is supported by Gyroflow.</p> <p>Footage from the following cameras are known to contain per-frame motion data:</p> <ul> <li>RED RAVEN</li> <li>???</li> </ul> <p>Footage from the following cameras contain asynchronous motion data:</p> <ul> <li>RED V-RAPTOR</li> <li>RED KOMODO</li> <li>??</li> </ul> <p>Make sure the camera firmware is updated, since older firmware versions may not have gyro logging enabled.</p>"},{"location":"cams/red/#stabilize-red-footage-with-gyroflow","title":"Stabilize RED footage with Gyroflow","text":"<p>In order to get the most out of RED footage, the following workflow is recommended:</p> <ol> <li>Transcode from R3D to ProRes. The resulting file can be loaded in Gyroflow as the video file</li> <li>Load the original .R3D in the \"Motion data\" section.</li> <li>Load the correct lens profile and do autosync.</li> <li>You can then render as ProRes or export a project file and open it in DaVinci Resolve with Gyroflow-OFX plugin and the original .R3D file to have full color control and stabilization inside Resolve without any quality loss</li> </ol> <p>Tips for KOMODO specifically: * Estimate gyro bias: Find a place where camera is not moving at all, right click on timeline and Estimate gyro bias here to calibrate the gyroscope * Enable rolling shutter correction and set frame readout time to 0.01ms (global shutter) * Do autosync, or better find 2-3 points on the timeline with significant motion and right click -&gt; Autosync here * If it's shaky, remove the sync point and try in a different place</p>"},{"location":"cams/red/#view-red-metadata-manually","title":"View RED metadata manually","text":"<p>If you wish to view the RED metadata without using Gyroflow, you can use REDline, a command-line utility bundled with REDCINE-X PRO (Windows, MacOS) or standalone program (Linux). See how to install and launch REDline based on your operating system in this guide.</p> <p>In order to view the per-frame metadata for a video file, run:</p> <pre><code>REDline --i video.R3D --printMeta 5\n</code></pre> <p>Assuming <code>REDline</code> is in the PATH, or e.g. <code>\"C:\\Program Files\\REDCINE-X PRO 64-bit\\REDline\" --i video.R3D --printMeta 5</code> on a Windows installation of REDCINE-X PRO.</p> <p>For a clip from a RED RAVEN, this yields:</p> <pre><code>FrameNo,Timecode,Timestamp,Aperture,Focus Distance,Focal Length,Acceleration X,Acceleration Y,Acceleration Z,Rotation X,Rotation Y,Rotation Z,Cooke Metadata\n0,20:47:06:03,,4.500000,455,10,0.087000,-0.019000,1.022000,0.189000,-0.001000,-2.253000,\n1,20:47:06:04,,4.500000,455,10,0.102000,-0.019000,1.007000,2.438000,-2.250000,-4.502000,\n2,20:47:06:05,,4.500000,455,10,0.102000,-0.019000,1.022000,2.438000,-0.001000,-2.253000,\n3,20:47:06:06,,4.500000,455,10,0.102000,-0.019000,1.007000,2.446000,-0.001000,-4.502000,\n4,20:47:06:07,,4.500000,455,10,0.087000,-0.003000,1.007000,2.446000,0.007000,-4.502000,\n5,20:47:06:08,,4.500000,455,10,0.087000,-0.019000,1.007000,2.446000,0.007000,-2.253000,\n6,20:47:06:09,,4.500000,455,10,0.087000,-0.019000,1.007000,2.438000,-0.001000,-0.004000,\n7,20:47:06:10,,4.500000,455,10,0.102000,-0.019000,1.007000,2.438000,-0.001000,-0.004000,\n8,20:47:06:11,,4.500000,455,10,0.102000,-0.019000,0.991000,2.438000,-0.001000,-0.004000,\n...\n</code></pre> <p>In order to view the asynchronous metadata, run:</p> <pre><code>REDline --i video.R3D --printMeta 7\n</code></pre> <p>This yields the following for a clip without this data:</p> <pre><code>[02-07-22-24-33-066]&lt;69f4&gt; Clip does not have async IMU data\n</code></pre>"},{"location":"cams/runcam/","title":"Runcam","text":"<p>The gyros in both the runcam 5 Orange and gocam PM GR can be sensitive to strong vibrations. You should therefore not rigidly mount it to a source of vibrations (e.g. Drone), but instead use either a TPU mount or similar. The runcam 5 seems to tolerate vibrations decently well, so standard TPU or foam mounts should suffice. From limited testing, the gocam may be more sensitive to motor noise, so see if you can find or 3D print something for better vibration isolation.</p>"},{"location":"cams/runcam/#runcam-5-orange","title":"Runcam 5 Orange","text":"<p>Surprise! All along the Runcam 5 Orange had an IMU hidden inside. This was of course previously used for the EIS, but with the newest versions of the firmware, the gyro and accelerometer data can be logged to a CSV file along with the video for post stabilization with Gyroflow. Find the firmware here: https://www.runcam.com/download/runcam5or </p> <p>The following have been found to be decent settings for the Runcam 5 Orange, with * indicating it's important for Gyroflow stabilization.</p> <ul> <li>Video quality: High</li> <li>Resolution*: Either 4K@30FPS(XV) or 1440p@60fps.<ul> <li>The XV resolution is actually the full 4:3 sensor stretched to a 16:9 image. So this gives the highest resolution and FOV.</li> <li>Note that the stretching looks bad, so if used without additional processing, linearly squeeze the width to 75% in the video editor to get a 4:3 image.</li> <li>The 1440p option is natively 4:3, so if you want 60fps use this one.</li> <li>You can also use one of the 16:9 resolutions, but this significantly reduces the available FOV for stabilization.</li> </ul> </li> <li>Volume: You decide</li> <li>Shutter*: Try to get a 90 to 180 degree shutter. So from 1/60 to 1/120 for 30fps and about 1/120 to 1/240 for 60 fps footage. (ND filter may be needed)</li> <li>ISO: As low as possible. There seems to be some auto gain regardless of settings.</li> <li>Color style: Normal (Flat squeezes the range and doesn\u2019t actually provide more dynamic range)</li> <li>Distortion correction*: Disabled</li> <li>Electronic Image Stabilization*: Disabled</li> <li>General settings (there were just found to work decently decently well, but do some testing yourself)</li> <li>Saturation: Medium</li> <li>Exposure compensation: 0</li> <li>Contrast: Low</li> <li>Sharpness: Low</li> <li>Metering: Average</li> <li>White balance: Sunny (change depending on scenario, don\u2019t use auto)</li> <li>Low light enhancement: you decide.</li> </ul>"},{"location":"cams/runcam/#file-processing","title":"File processing","text":"<p>Note</p> <p>This was required for the initial gyro logging firmware, and may not be applicable with the latest firmware.</p>  <p>With the initial gyro logging firmware for the Runcam 5, it had an issue with occasionally generating a duplicate frame, which leads to jitter in the stabilized output. This could be fixed by the time you read this, but otherwise there\u2019s a way to solve it. FFmpeg has a command which can detect and remove duplicate frames. I will assume you already have FFmpeg available in the command line, if not, install it from ffmpeg.org.</p> <p>Duplicate frame detection: <pre><code>Run: ffmpeg -i INPUTVIDEOFILE.mp4 -vf mpdecimate=hi=64:lo=32:frac=0.1 -loglevel debug -f null -\n</code></pre> After a few seconds, you'll see this: </p> <p>Typically there\u2019s a duplicate frame every 30 seconds. If the input and output frames are the same, then it isn\u2019t an issue. If they are different, we need to get rid of the duplicate frames using the following command:</p> <p><pre><code>ffmpeg -i RC_0001_210724181232.MP4 -vf mpdecimate=hi=64:lo=32:frac=0.1,setpts=N/FRAME_RATE/TB -c:v libx264 -crf 18 RC_0001_filtered.mp4\n</code></pre> (replace with your filenames). Lower value for <code>-crf</code> means less compression</p> <p>If using an nvidia GPU (faster processing):</p> <p><pre><code>ffmpeg -i RC_0001_210724181232.MP4 -vf mpdecimate=hi=64:lo=32:frac=0.1,setpts=N/FRAME_RATE/TB -c:v h264_nvenc -b:v 50M RC_0001_filtered.MP4\n</code></pre> The 50M means encoding at 50 Mbps, change if needed. Replacing <code>h264_nvenc</code> with <code>h264_amf</code> should work for AMD systems</p> <p>In Gyroflow</p> <ul> <li>If using 4K XV, use the preset: <code>RunCam/Runcam_5_Orange_4K_30FPS_XV_16by9_stretched.json</code></li> <li>If using 1440p 60fps use: <code>RunCam/Runcam_5_Orange_1440p_4by3.json</code></li> <li>Low pass filter at about <code>60 Hz</code> should be fine</li> </ul> <p>Note: Gyroflow v1.0.0-rc1 does not yet support the 4K XV option right away (will be added shortly). Use <code>adjust parameters</code> and change the first <code>Pixel focal length</code> value from <code>1503.650975788249</code> to <code>2004.868</code>: </p>"},{"location":"cams/runcam/#gocam-pm-gr","title":"GOCam PM GR","text":"<p>Depending on your setup, you might need to softmount this cam, since the the gyro can be sensitive to motor noise vibrations.</p>"},{"location":"cams/runcam/#settings","title":"Settings","text":"<p>First of all, download the latest firmware.</p> <p>With the initial firmware, the only 4:3 resolution is 1440p 60fps. If you want the full sensor use that. Otherwise use the 4K resolution (works fine if you end up cropping to a cinematic aspect ratio)</p>"},{"location":"cams/runcam/#in-gyroflow","title":"In Gyroflow","text":"<ul> <li>Use either the <code>RunCam/Runcam_Iflight_Gocam_1440p_4by3.json</code> preset or the <code>RunCam/Runcam_Iflight_Gocam_PMGR_4K_16by9.json</code> preset depending on setting</li> <li>A 50 Hz low pass filter setting is a good starting point.</li> </ul>"},{"location":"cams/smartphones/","title":"Smartphones","text":"<p>Smartphones contains IMU's and allow for gyro logging.</p>"},{"location":"cams/smartphones/#ios-apps","title":"IOS apps","text":"<p>GyroCam - Professional Camera is a camera app with gyro logging support designed to be compatible with Gyroflow. </p> <p>The following are motion data logging apps which can be used with Gyroflow:</p> <ul> <li>G-Field Recorder</li> <li>Gyro - Record Device Motion Data</li> <li>Sensor Logger</li> </ul>"},{"location":"cams/smartphones/#android-apps","title":"Android apps","text":"<p>The following are gyro data loggers for Android which can be used with Gyroflow:</p> <ul> <li>Sensor Logger</li> <li>Sensor Record</li> </ul>"},{"location":"cams/sony/","title":"Sony","text":"<p>The following cameras are capable of native gyro data logging: a1, a7c, a7r IV, a7 IV, a7s III, a9 II, FX3, FX6, RX0 II, RX100 VII, ZV1, ZV-E10</p> <p>This data is designed for use with Sony's Catalyst Browse stabilization which cannot stabilize footage shot with third-party lenses. Gyroflow supports reading this metadata natively, thus giving access to more smoothing algorithms and support for third-party lenses.</p>"},{"location":"cams/sony/#general","title":"General","text":"<p>It has been found that the above mentioned Sony cameras do not record motion data when capturing at 120 fps.</p>"},{"location":"cams/sony/#sony-a1a7ca7r-iva7-iva7s-iiia9-ii","title":"Sony a1/a7c/a7r IV/a7 IV/a7s III/a9 II","text":"<p>Since these cameras contain mechanical in-body image stabilization, this should be disabled when using Gyroflow. Even disabled, the sensor may still shift around in the presence of vibrations or strong accelerations. This is unlikely to be an issue with hand-held footage, but your mileage may vary.</p>"},{"location":"contrib/documentation/","title":"Documentation","text":""},{"location":"contrib/documentation/#help-with-documentation","title":"Help with documentation","text":"<p>This site uses MkDocs and Material for MkDocs and is formatted with Markdown. Here's how to serve a local version for editing purposes</p> <ol> <li>Install MkDocs and Material for MkDocs: <code>pip install mkdocs-material</code></li> <li>Clone the repo: <code>git clone https://github.com/gyroflow/gyroflow-docs.git</code></li> <li>Run local server: <code>mkdocs serve</code></li> </ol> <p>Alternatively each page has an edit button which directly opens the GitHub online editor.</p> <p>In general, create GitHub pull request to merge the edits.</p>"},{"location":"contrib/documentation/#mkdocsmarkdown-examples","title":"MkDocs/Markdown examples","text":"<p>Note</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>   <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>   <p>This is a warning</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>  <p>Image with lightbox: <p>Image title</p></p> <p>This is some text with a footnote1.</p> <p>Here's a LaTeX math block rendered using MathJax $$ c = \\sqrt{a^2 + b^2} $$</p> <p>Here's a Python code block with line numbers</p> <pre><code># Generate 24 different (right handed) orientations using cross products\ndef generate_rotmats():\n    basis = [[1,0,0], [0,1,0], [0,0,1], [-1,0,0], [0,-1,0], [0,0,-1]] # Six different unit vectors\n    basis = [np.array(v) for v in basis]\n    ORIENTATIONS = []\n\n\n    for i in range(len(basis)):\n        for j in range(len(basis)):\n            if i != j and (i + 3) % 6 != j:\n                ivec = basis[i]\n                jvec = basis[j]\n                kvec = np.cross(ivec,jvec)\n                mat = np.vstack([ivec, jvec, kvec]).transpose()\n                ORIENTATIONS.append(mat)\n</code></pre>   <ol> <li> <p>Content of the footnote\u00a0\u21a9</p> </li> </ol>"},{"location":"contrib/gyroflow/","title":"Contribute to Gyroflow","text":"<p>For contributing to the main Gyroflow program, refer to the Github repository. Feature requests can be submitted by opening issues, and new features can be added through pull requests.</p> <p>Another way of contributing to the project is by helping translate the program to your language. This is done through crowdin: https://crowdin.com/project/gyroflow.</p> <p>Currently Gyroflow is available in:</p> <ul> <li>English (base language)</li> <li>Polish (by AdrianEddy)</li> <li>German (by Grommi and Nicecrash)</li> <li>Danish (by ElvinC)</li> <li>Norwegian (by MiniGod and alexagv)</li> <li>Chinese Simplified (by DusKing1)</li> <li>Chinese Traditional (by DusKing1)</li> </ul> <p>Furthermore, you can contribute to the Gyroflow project by creating and submitting new lens profiles. This allows future users with the same hardware to start using the software right away.</p>"},{"location":"contrib/support/","title":"Support Gyroflow / Contributors list","text":"<p>The Gyroflow project was initially a Python program started by Elvin in 2020. Elvin is currently one of the developers working on software and hardware development:</p> <p>Support Elvin via Patreon </p> <p>Version 1.0 and onwards was made possible by AdrianEddy, who worked overtime on adapting the previous Python codebase to high-performance cross-platform Rust code with a modern UI, and implemented new advanced features like rolling shutter correction. You can find AdrianEddy on Github:</p> <p>AdrianEddy</p>"},{"location":"contrib/support/#other-contributors","title":"Other contributors","text":"<p>Other amazing contributors have helped during the development by discussing, testing, and implementing new ideas for video stabilization, both for the previous Python version and the current software. Some of these people are:</p> <ul> <li>Aphobius - Author of velocity dampened smoothing algorithm</li> <li>Marc Roeschlin - Author of adaptive zoom algorithm</li> <li>alexagv - Investigated advanced rendering options for the Python version</li> <li>nivim - Work on insta360 support for the Python version</li> <li>MiniGod - Investigated sync-less GoPro stabilization</li> <li>Gro2mi - Work on automatic lens calibration and sync for the Python version</li> <li>DusKing1 - Hardware development and translations for Gyroflow</li> <li>NiceCrash - Started a community around FPV video stabilization and has been an alpha/beta tester with involvement from the very beginning of the project</li> </ul> <p>Finally, a huge thanks goes out to everyone who provided sample footage during the development. This has made it possible to natively support a wide range of cameras and gyro sources. Fun fact: Elvin did not own a suitable camera for testing in the initial months of the project, so Gyroflow would literally not have been made without everyone's willingness to help.</p>"},{"location":"flowshutter/clist/","title":"Supported Camera","text":"<p>Welcome to the Camera List. To navigate through this section, use the sidebar on the right.</p> <p>At the time of writing, the lists below are not complete and needs further updating. If you know of a certain camera's way of REC triggering, please let us know via:</p> <ul> <li>Flowshutter issue</li> <li>Gyroflow Discord</li> </ul>"},{"location":"flowshutter/clist/#sony-multi-terminal-protocol","title":"Sony Multi-Terminal Protocol","text":"<p>It seems that any camera from Sony that has this Multi-USB port can use this protocol for REC triggering.</p> <p>How to make Sony Multi USB connector? Wiring?</p>    Camera Support info Camera Support info Camera Support info     A5000 yes A7S yes A7R yes   A5100 yes A7S2 yes A7R2 yes   A6000 yes A7S3 yes A7R3 yes   A6100 yes A7M yes A7R4 yes   A6300 yes A7M2 yes FX3 yes   A6400 yes A7M3 yes FX6 yes   A6500 yes A7M4 yes FX9 yes   A6600 yes A7C no FS5 yes"},{"location":"flowshutter/clist/#momentary-ground","title":"Momentary Ground","text":"<p>As the name implies, momentarily shorting a pin in one of the camera's port(s) to ground triggers REC start/stop. Many cameras support triggering REC using this method.</p> <p>Wiring Diagrams</p>    Brand Model Support info Notes     Blackmagic Design Pocket Cinema Camera 4k yes w/ZITAY recording cable   Blackmagic Design Pocket Cinema Camera 6k yes w/ZITAY recording cable   Blackmagic Design Pocket Cinema Camera 6k pro yes w/ZITAY recording cable   Kinefinity MAVO LF 6k yes    Kinefinity MAVO Edge 6K yes    Kinefinity MAVO Edge 8K yes    RED DSMC2 yes    RED RANGER yes    Panasonic Lumix DMC-GH1 yes w/Panasonic Custom Trigger Connector   Panasonic Lumix DMC-GH2 yes w/Panasonic Custom Trigger Connector   Panasonic Lumix DMC-GH3 yes w/Panasonic Custom Trigger Connector   Panasonic Lumix DMC-GH4 yes w/Panasonic Custom Trigger Connector   Panasonic Lumix DMC-GH5 yes w/Panasonic Custom Trigger Connector   Panasonic Lumix DC-GH5S yes w/Panasonic Custom Trigger Connector   More.. To Be Appended"},{"location":"flowshutter/clist/#33v-schmitt-trigger","title":"3.3V Schmitt Trigger","text":"<p>Pull a pin of a port to 3.3V level to start REC, and pull it back to 0V to stop REC.</p>    Brand Model Support info     RED DSMC yes   RED DSMC2 yes"},{"location":"flowshutter/clist/#zcam-uart-protocol","title":"ZCAM UART protocol","text":"<p>All ZCAM cameras are theoretically supported, but have only been verified on the E2 series.</p>    Model Support info Note Model Support info Note     E2 yes  E2-S6 yes    E2C no  E2-F6 yes    E2G yes  E2-F8 yes    E2-M4 yes  E2-S6G yes"},{"location":"flowshutter/clist/#todo","title":"TODO","text":""},{"location":"flowshutter/flowshutter/","title":"Overview","text":"<p>Flowshutter is a custom camera remote. When used in conjunction with readily available hardware, this results in a flexible and reliable external camera motion logger for Gyroflow. It can provide precise synchronization of camera video recording and motion logger (betaflight/emuflight FC) recording.</p> <p>It was designed to be used with the Gyroflow software to provide you one of the best open source video stabilization experiences.</p>"},{"location":"flowshutter/flowshutter/#features","title":"Features","text":"<ul> <li>\"1-click\" - synchronously start/stop (1) FC arm (2) camera recording</li> <li>\"Audio injection\" - inject sync marker to the audio track for precise synchronization between video and gyro data</li> <li>OLED Display - show the device information and allow user to change settings without hacking the firmware code</li> <li>Blackbox Erasion - erase all blackbox data without connecting to the computer</li> </ul>"},{"location":"flowshutter/flowshutter/#supported-hardware","title":"Supported Hardware","text":"<p>NeutronRC has been continuously cooperating with us on commercial hardware development, and their commercial version of flowshutter is our first recommended choice.</p>  <p>For more info about list of supported hardware, please check Supported Hardware.</p>"},{"location":"flowshutter/flowshutter/#compatible-camera-protocoltrigger-mechanisms","title":"Compatible camera protocol/trigger mechanisms","text":"<ul> <li>Sony Multi-Terminal Port USB Protocol</li> <li>Momentary Ground</li> <li>3.3V Schmitt Trigger</li> <li>ZCAM UART protocol</li> <li>Sony LANC protocol*</li> <li>(WIP) 5V Schmitt Trigger</li> <li>(WIP) HDMI CEC protocol</li> </ul> <p>Check out our list of Supported Camera for more details.</p>  <p>Note</p> <ul> <li>Sony LANC protocol need an extra LANC controller, an Arduino example code is available here.</li> </ul>"},{"location":"flowshutter/flowshutter/#compatible-fc","title":"Compatible FC","text":"<ul> <li>Flowbox (highly recommended)</li> <li>Modern FC with BMI270 gyro (recommended)</li> <li>Any other FC that support CRSF protocol</li> </ul>"},{"location":"flowshutter/flowshutter/#more-info","title":"More info","text":"<ul> <li>Source code: https://github.com/gyroflow/flowshutter</li> <li>Development Guide: https://github.com/gyroflow/flowshutter#development-guide</li> </ul>"},{"location":"flowshutter/hardware/","title":"List for Supported Hardwares","text":"<p>Welcome to the Hardware List. To navigate through this section, use the sidebar on the right.</p> <p>This page shows infomation on certain hardware that is supported by flowshutter. More and more manufacturers are adding support for new hardware and new feature based on that, so this list is not exhaustive and keeps growing.</p>"},{"location":"flowshutter/hardware/#neutronrc-sdb","title":"NeutronRC SDB","text":"<p>NeutronRC Stabilization Data Box</p>"},{"location":"flowshutter/hardware/#general-overview","title":"General Overview","text":""},{"location":"flowshutter/hardware/#specification","title":"Specification","text":"<ul> <li>Bone-like shape, 43 x 18 x 10mm</li> <li>Nylon sintered case with acrylic panel</li> <li>Adjustable cold shoe mounts (for different mounting postions and/or orentations)</li> <li>Built-in 600mah battery (enough for 5 hours of working)</li> <li>Built-in power switch</li> <li>Built-in battery charger and indicator</li> <li>Built-in single track MEMS microphone</li> <li>Dual layer design with flowbox built-in (F411 + BMI270 + 128MB blackbox)</li> <li>Separate USB-C's of flight controller and flowshutter</li> <li>Dual 3.5mm jack for camera controlling and audio injection</li> </ul>"},{"location":"flowshutter/hardware/#links","title":"Links","text":"<ul> <li>Taobao (\u6dd8\u5b9d)</li> <li>AliExpress</li> <li>NewBeeDrone will be one of the resellers of this product soon!</li> </ul>"},{"location":"flowshutter/hardware/#diy-fc-sized","title":"DIY (FC Sized)","text":"<p>This scheme was designed by us to take advantage of the old 30x30 size flight controller.</p>"},{"location":"flowshutter/hardware/#general-overview_1","title":"General Overview","text":""},{"location":"flowshutter/hardware/#specification_1","title":"Specification","text":"<ul> <li>FC shape, holes 30.5 x 30.5mm, size 38 x 40 mm</li> <li>Bare PCB</li> <li>2-6s input voltage range (7.4V to 22.2V)</li> <li>Dual buttons for each button IO</li> <li>Solder pads for camera controlling and audio injection IOs</li> <li>Easy to DIY</li> </ul>"},{"location":"flowshutter/hardware/#links_1","title":"Links","text":"<ul> <li>FC size: build video is here</li> </ul>"},{"location":"flowshutter/hardware/#diy-credit-card-sized","title":"DIY (Credit Card Sized)","text":""},{"location":"flowshutter/hardware/#general-overview_2","title":"General Overview","text":""},{"location":"flowshutter/hardware/#specification_2","title":"Specification","text":"<ul> <li>Credit card shape, holes 47.6 x 28.3 mm,  shape 50 x 32 mm</li> <li>18650 battery case support</li> <li>On-board power switch</li> <li>On-board battery charger and indicator</li> <li>Solder pads for camera controlling and audio injection IOs</li> <li>Easy to DIY</li> </ul>"},{"location":"flowshutter/hardware/#links_2","title":"Links","text":"<ul> <li>Credit card size: build video is here</li> </ul>"},{"location":"flowshutter/quickstart/","title":"Quick Start for Flowshutter","text":"<p>This page assumes that you are using a commercial version of Flowshutter (depending on the manufacturer, it may be called differently, such as \"stabilization box\", \"stabilization data box\", \"flowshutter box\", etc), these commercial hardwares often contain a flowshutter board and a betaflight flight controller, as a whole. On this page we refer to these wholes as Flowshutter.</p>  <p>If you are using a DIY flowshutter, then you should clearly separate your flight controller from the flowshutter, and carefully consider the specific configuration of the corresponding parts in this tutorial on your own build.</p>"},{"location":"flowshutter/quickstart/#meet-the-hardware","title":"Meet the hardware","text":"<p>Although hardware from different manufacturers varies, their main components should be the same - necessary parts of the flowshutter device/firmware to work properly.</p> <p>At the time of writing this page, I only have the commercial version of NeutronRC hardware - NeutronRC SDB, so this page will give you a quick start based on that.</p>"},{"location":"flowshutter/quickstart/#oled-screen","title":"OLED screen","text":"<p>Flowshutter currently only support a single OLED screen, with 128x32 pixels.</p>"},{"location":"flowshutter/quickstart/#buttons","title":"Buttons","text":"<p>Flowshutter requires two physical buttons to complete the interaction, they are the PAGE button and the ENTER button</p>"},{"location":"flowshutter/quickstart/#camera-control-port","title":"Camera control port","text":"<p>Flowshutter's control of the camera is achieved through the connection of physical wires to transmit control signals. So in order to be able to control your camera properly, you should use this port to properly connect with the camera's control interface.</p>"},{"location":"flowshutter/quickstart/#flowshutter-usb-chargeesp32-usb","title":"Flowshutter USB (Charge/ESP32 USB)","text":"<p>This interface is used to upgrade the flowshutter firmware. </p>  <p>Please note the difference between \"Flowshutter\" and \"flowshutter\", the former is a physical entity, and the latter refers specifically to the firmware.</p>"},{"location":"flowshutter/quickstart/#fc-usb-flowbox-usb","title":"FC USB (Flowbox USB)","text":"<p>This interface is use to configure the flight controller (motion data logger), and export motion data.</p>"},{"location":"flowshutter/quickstart/#mount-it-to-your-camera","title":"Mount it to your camera","text":"<p>Please mount Flowshutter rigidly to your camera. For use in high-vibration environments (such as a large X8 drone), be sure to take vibration reduction measures for the camera as a whole.</p>  <p>You may have concerns about the installation orientation, but it doesn't matter, we have many flexible ways to offset the impact of different installation orientations. The easiest way will be introduced in the next section.</p>"},{"location":"flowshutter/quickstart/#config-it-for-your-camera","title":"Config it for your camera","text":""},{"location":"flowshutter/quickstart/#select-camera-protocol","title":"Select camera protocol","text":""},{"location":"flowshutter/quickstart/#select-device-mode","title":"Select device mode","text":""},{"location":"flowshutter/quickstart/#reboot-device","title":"Reboot device","text":""},{"location":"flowshutter/quickstart/#config-logger-part","title":"Config logger part","text":"<ol> <li>Connecting FC to computer, open betaflight configurator and connect to FC (flowbox)</li> <li>Change orientation in <code>Configuration</code> tab, until the drone's movement matched up with your camera movement in <code>Setup</code> tab.</li> </ol>"},{"location":"flowshutter/quickstart/#exatracting-motion-data","title":"Exatracting motion data","text":""},{"location":"flowshutter/quickstart/#connecting-fc-to-computer","title":"Connecting FC to computer","text":""},{"location":"flowshutter/quickstart/#activating-msc-mode","title":"Activating MSC mode","text":"<p>In configurator, <code>Blackbox</code> tab, click <code>Activate MSC</code> button. </p>"},{"location":"flowshutter/quickstart/#copy-motion-data","title":"Copy motion data","text":"<p>Then the FC will become a readable USB drive, and you can copy the motion data from it to your computer. </p>"},{"location":"flowshutter/quickstart/#flash-firmware","title":"Flash firmware","text":"<p>For some special reason, it may be necessary to flash a new firmware in some cases, such as:</p> <ul> <li>The new firmware adds control support to your camera</li> <li>The new firmware has features you desperately need</li> <li>The new firmware fixes a bug you're currently experiencing</li> </ul> <p>The following will briefly introduce the steps of firmware upgrade for you in the simplest way.</p>"},{"location":"flowshutter/quickstart/#flash-flowshutter-firmware","title":"Flash flowshutter firmware","text":"<ol> <li>Download uPyCraft IDE</li> <li>Download flowshutter firmware from GitHub release</li> <li>(Optional) Download and install CH340 driver for your computer</li> <li>Open uPyCraft IDE</li> <li>Connect Flowshutter USB to your computer</li> <li><code>uPyCraft IDE</code> -&gt; <code>Tools</code> -&gt; <code>BurnFirmware</code></li> <li>Configure burning parameters as below: </li> <li>Hit <code>OK</code> and wait until it finishes </li> </ol>"},{"location":"flowshutter/quickstart/#flash-fc-firmware","title":"Flash FC firmware","text":"<ol> <li>Download betaflight configurator from Betaflight configurator release</li> <li>Connect your FC (flowbox) to your computer</li> <li><code>Firmware Flasher</code> tab -&gt; <code>STM32F411</code> -&gt; <code>4.3</code> -&gt; <code>Load Firmware [Online]</code> -&gt; <code>Flash Firmware</code></li> <li>Add gyroflow <code>logger-presets</code> as third party preset source. Check this page and/or this page for more information.</li> <li>Connect to FC -&gt; <code>Presets</code> tab -&gt; pick and apply the cooresponding <code>gyroflow preset</code> for your device, e.g. NeutronRC SDB should pick <code>NeutronRC SDB</code> preset.</li> </ol>"},{"location":"flowshutter/settings/","title":"Settings Explanation","text":"<p>Flowshutter has many settings to allow you to use it in different situations. This page contains a short description and guide to each of the settings. Luckily, many of the settings are self-explanatory.</p>"},{"location":"flowshutter/settings/#user-interaction-system","title":"User Interaction System","text":"<p>There are two or three buttons on the flowshutter:</p> <ul> <li>two buttons: Page Down and Enter</li> <li>three buttons: Page Up, Enter and Page Down</li> </ul> <p>To use them, you need to press, hold and release, which will trigger the short/long press event depending on the hold time. The threshold for short/long press is 500ms, longer than 50ms and shorter than 500ms will trigger a short press event, and longer than 500ms will trigger a long press event.</p>"},{"location":"flowshutter/settings/#reboot-menu","title":"Reboot menu","text":"<p>On homepage, long press the Enter button and it will show the reboot menu.</p> <ul> <li>Page *: toggle between different reboot options</li> <li>Enter:: react to that option</li> </ul> <p>And the reboot options are:</p> <ul> <li><code>Exit</code>: exit the reboot menu</li> <li><code>Reboot</code>: reboot the device</li> </ul>"},{"location":"flowshutter/settings/#battery-info","title":"Battery info","text":"<p>On home page, short press the Page * button and it will show the battery info.</p> <p>You can short press the Page * button to leave the battery info and back to homepage</p>"},{"location":"flowshutter/settings/#device-menu","title":"Device menu","text":"<p>On homepage, long press the Page * button and it will show the device menu.</p> <ul> <li>Page *: switch the submenu</li> <li>Enter: enter the submenu</li> </ul> <p>In each submenu, we have three options:</p> <ul> <li><code>Leave</code>: leave the submenu and back to overview state</li> <li><code>Save</code>: save the settings to the device</li> <li>A setting: that can be changed to enable/disable the feature</li> </ul> <p>you can short press the Page * button to switch the option, and short press Enter to apply/into that option.</p> <p>When hovering over a specific setting, you can also short press Enter to enter/exit alignment changes, and use Page * to toggle options while making changes.</p> <p>You can then long press Page * in the overview state of any submenu to return to the homepage.</p>"},{"location":"flowshutter/settings/#camera-protocol","title":"Camera protocol","text":"<p>Used to specify how the flowshutter interacts with the camera.</p> <ul> <li><code>NO</code>: NO interact with the camera</li> <li><code>MMTRY GND</code>: Momentary Ground on GPIO 25 (TX2)</li> <li><code>3V3 Schmitt</code>: 3.3V Schmitt Trigger on GPIO 26 (RX2)</li> <li><code>Sony MTP</code>: Sony Multi-Terminal Port USB Protocol on UART2</li> <li><code>ZCAM</code>: ZCAM UART protocol on UART2</li> </ul> <p>When you change the camera protocol, please restart when you receive the restart prompt on the OLED to ensure that the relevant hardware devices are properly applied / the microcontroller is properly initialized.</p>  <p>Warning</p> <p>Do not use the wrong camera protocol on devices that do not match. Otherwise, there may be a crash/port burnout/equipment loss of warranty or even fire!</p>  <p>Other protocols/mechenisms are under development.</p>"},{"location":"flowshutter/settings/#device-mode","title":"Device mode","text":"<p>Used to specify how the flowshutter works with the camera.</p> <ul> <li><code>SLAVE</code>: The flowshutter is a slave device. It can passively monitor the camera recording state and toggle FC ARM/DISARM correspondingly.</li> <li><code>MASTER</code>: The flowshutter is a master device. It can actively trigger camera record/stop and FC ARM/DISARM.</li> <li><code>MASTER/SLAVE</code>: The flowshutter is a master/slave device. It can actively trigger camera record/stop and FC ARM/DISARM, or it can passively monitor the camera recording status to trigger FC ARM/DISARM.</li> </ul>"},{"location":"flowshutter/settings/#injection-mode","title":"Injection mode","text":"<p>Used to specify whether flowshutter injects sync markers on the camera's audio track. This is so called \"Audio Injection\" feature.</p> <ul> <li><code>ON</code>: Inject 25Hz sync marker on one of the audio track.</li> <li><code>OFF</code>\uff1aNo sync marker injection.</li> </ul>"},{"location":"flowshutter/settings/#blackbox-erase","title":"Blackbox erase","text":"<p>Used to erase the blackbox data of the flowshutter.</p> <ul> <li><code>Erase stop</code>: Stop the erase process.</li> <li><code>Erasing...</code>: Start the erase process.</li> </ul> <p>Once you hear a two short beep from the FC, it means the erase process is done.</p>  <p>Warning</p> <p>The erasing process cannot be cancelled and the erased data cannot be retrieved!</p>"},{"location":"flowshutter/wiring/","title":"Wiring to Camera","text":"<p>This page shows you some common wiring methods and precautions to use with the Flowshutter. We are working on adding support for more are more camera protocol/triggering methods, so this list is not exhaustive and keeps growing.</p>"},{"location":"flowshutter/wiring/#sony-multi-usb","title":"Sony Multi-USB","text":"<p>Sony Multi-Terminal USB interface is/maybe a Sony proprietary intellectual property.</p>  <p>This interface is commonly found on the micro SLR/SLR/movie machine that Sony has launched in recent years. There is often a \"MULTI\" mark around this interface to indicate \"Multi Terminal\". </p> <p>Correspond to Sony Multi-Terminal Protocol.</p>   <p>It should be noted that there is a resistor pad on the other side of the USB splint, and a resistor with a resistance value greater than 100K needs to be soldered on it so that the interface can be correctly recognized by the Sony camera.</p>   <p>Another type of connector does not place a resistor pad on the splint, so a 100K resistor needs to be connected in series between the pin labeled 6 and GND.</p>"},{"location":"flowshutter/wiring/#momentary-ground","title":"Momentary Ground","text":"<p>Correspond to Momentary Ground.</p>  <p>Different cameras may have different interfaces/ports, please be sure to wire them correctly, otherwise it may cause the device to short circuit / lose warranty or even burn.</p>"},{"location":"flowshutter/wiring/#bmpcc-4k6k6k-pro-recording-cable-zitay","title":"BMPCC 4k/6k/6k Pro Recording Cable (ZITAY)","text":"<p>ZITAY Official Link</p> <p>It is worth mentioning that this Recording Cable from ZITAY actually wraps an HDMI-CEC controller based on <code>STM32F051</code> MCU under its gum shell. It is recommended to remove its shell and rewire it for using with Flowshutter.</p>"},{"location":"flowshutter/wiring/#panasonic-lumix-remote-connector","title":"Panasonic LUMIX Remote Connector","text":"<p>Panasonic/LUMIX uses special voltage/resistance detection mechanism to trigger the REC start/stop, therefore, please note that when using this brand of camera, a 2.5mm four-pin connector must be used to insert the REMOTE port of the camera body, and additional circuits need to be built with resistors so that the signal can be recognized by the camera.</p>"},{"location":"flowshutter/wiring/#33v-schmitt-trigger","title":"3.3V Schmitt Trigger","text":"<p>Correspond to 3.3V Schmitt Trigger.</p>  <p>Different cameras may have different interfaces/ports, please be sure to wire them correctly, otherwise it may cause the device to short circuit / lose warranty or even burn.</p>"},{"location":"guide/calibration/","title":"Camera Calibration","text":"<p>The purpose of the camera calibration process is to accurately determine the intrinsic parameters of a camera system. This consists of:</p> <ul> <li>focal length</li> <li>lens distortions</li> <li>other misalignments during the imaging process.</li> </ul> <p>These parameters can be found through Lens Calibration, which consists of imaging a known pattern, and analyzing the resulting footage. The Gyroflow lens calibrator looks like this:</p> <p>Related to lens calibration is estimating the rolling shutter frame readout time. Most DSLR's and consumer-grade video cameras use a rolling shutter sensors, which introduce warps and distortions in moving footage. It is highly recommended to get an accurate estimate of the rolling shutter before lens calibration and fill in the value in the calibration utility, but it can be done afterwards as well. Please have a look at gyroflow/rollingshutter for an accurate method of measuring rolling shutter or below for an estimated approach.</p>"},{"location":"guide/calibration/#video-guide","title":"Video Guide","text":"<p>Nurk FPV's tutorial contains a calibration example:</p>"},{"location":"guide/calibration/#getting-calibration-footage","title":"Getting calibration footage","text":"<ol> <li>Display the calibration pattern on a flat computer monitor, preferably in full screen (available from the lens calibrator utility). You can also print it out if you prefer. In general, larger calibration patterns are preferred since focus will be closer to the focus during actual use, so use your largest screen/monitor. A bright screen with a slightly darkened room works well.</li> <li>Select the desired camera settings to calibrate for. Most importantly the field of view/focal length and aspect ratio, if applicable. Framerate and resolution doesn't matter, only if the resolution changes the field of view. Too low shutter speed may also cause undesirable motion blur.</li> <li>Record the pattern while slowly moving around to different angles and distances in one clip. 60 seconds is typically enough. Try to avoid motion blur and rolling shutter distortion with slow and steady movements, and make sure the full chessboard is in view. The following angles are recommended for getting distortion information from the full frame:</li> <li>Chessboard filling whole frame</li> <li>Chessboard seen from distance.</li> <li>Chessboard seen at an angle.</li> <li>Each edge of video frame aligned with edge of chessboard.</li> <li>Corner of chessboard aligned with corner of video.</li> <li>Finally, get fast motion for rolling shutter reference/estimation by doing a fast side-to-side yaw motions with the camera. This will produce rolling shutter effect where the lines will be bent, instead of straight.</li> </ol> <p>The calibration pattern can be displayed from the calibration utility. Alternatively, the default (14x8 radon) calibration pattern is available here: </p> <p>The previous default (14x8 chessboard) calibration pattern is also available below: </p> <p>Tip: Larger calibration patterns allow for more representative focal distance. Try using the largest screen available, especially with larger lenses.</p>"},{"location":"guide/calibration/#creating-camera-preset","title":"Creating camera preset","text":"<ol> <li>Start the Gyroflow tool and click <code>create new</code> under the lens profile tab.</li> <li>Open the previously recorded calibration video file.</li> <li>Either begin auto calibration or manually add frames using <code>add calibration point</code> from the timeline context menu. Note: Skip the final fast side-to side motion during this step.</li> <li>After either the automatic or manual calibration process, check the <code>reprojection error</code>. This value describes the overall error between the preset and actual lens distortion based on the expected features of the calibration pattern.</li> <li>After all required frames are added and processed, the straight lines should be straight in the undistorted video. Reprojection error should typically be under 5 (pixels) with excellent calibrations giving values below 1.</li> <li>Fill in the preset information and export the lens profile. Try to add all relevant information about the camera/lens combination including field of view setting and lens focal length if applicable.</li> <li>If rolling shutter information is known in advance, fill in the frame readout time.</li> <li>If a successful calibration was achieved with a low reprojection error and no obvious artefacts, the profile can be submitted with the <code>Upload lens profile to the database</code> checkbox.</li> <li>You're now ready to use the new lens preset. These are stored as <code>.json</code> files.</li> </ol>"},{"location":"guide/calibration/#estimating-rolling-shutter","title":"Estimating rolling shutter","text":"<p>If your calibration video has matching gyro data, the following approach can be used to check the stabilization and estimate the rolling shutter visually. This method only works if the calibration clip had matching gyro data.</p> <p>An alternative and much more accurate method doesn't require gyro data, but instead requires an Arduino+LED or similar to generate a precise blinking frequency at e.g. 1 KHz. If you have the hardware, this is recommended over the visual method since it's an order of magnitude more accurate. Read more at gyroflow/rollingshutter.</p> <p>The visual method is as follows: 1. Load the same clip in main window, load the lens profile you just calibrated, sync the gyro with video. 2. Focus on that fast sideways motion part, go to Stabilization -&gt; Rolling shutter correction, and move the slider until the rolling shutter effect is fixed, ie. the lines become straight and are not bent anymore. You may need to reverse the rolling shutter direction. 3. Edit your created lens profile json with notepad, and replace <code>\"frame_readout_time\": null,</code>, to e.g. <code>\"frame_readout_time\": 15.5,</code>  (15.5ms is an example value). This value will automatically be applied when using this preset.</p>"},{"location":"guide/calibration/#additional-calibration-options","title":"Additional calibration options","text":"<p>The lens calibrator contains additional options.</p>"},{"location":"guide/calibration/#default-output-size","title":"Default output size","text":"<p>Radial lens undistortion typically results in the image being stretched more in the horizontal axis (use the FOV slider to see this). For instance, undistorted 4:3 GoPro video:</p>  <p>Notice that the area of the valid rectangle is close to a 16:9 aspect ratio as opposed to 4:3. In these cases, the default output size can be modified to a 16:9 one.</p> <p>For cameras with minimal fisheye distortion, or even with pincushion distortion, the resulting valid aspect ratio is close to the original one. For these cameras, just use the input resolution for the default output size.</p>"},{"location":"guide/calibration/#sharpness-limit","title":"Sharpness limit","text":"<p>Sets the minimum required sharpness for the calibration pattern. If the pattern failed to detect due to focus or blurriness, try increasing this limit.</p>"},{"location":"guide/installation/","title":"Installation","text":""},{"location":"guide/installation/#minimum-system-requirements","title":"Minimum system requirements:","text":"<p>Here are the Gyroflow minimum requirements:</p> <ul> <li>Windows 10 64-bit (1809 or later)<ul> <li>Windows \"N\" versions: Install the \"Media Feature Pack\", go to Settings -&gt; Apps -&gt; Optional features -&gt; Add a feature -&gt; Select \"Media Feature Pack\" -&gt; Click Install</li> </ul> </li> <li>macOS 10.14 or later (both Intel and Apple Silicon are supported natively)</li> <li>Linux: <ul> <li><code>.tar.gz</code> package (recommended): Debian 10+, Ubuntu 18.10+, CentOS 8.2+, openSUSE 15.3+. Other distros require glibc 2.28+ (<code>ldd --version</code> to check)</li> <li><code>.AppImage</code> should work everywhere</li> <li>Make sure you have latest graphics drivers installed</li> <li>Possibly needed packages: <code>sudo apt install libva2 libvdpau1 libasound2 libxkbcommon0 libpulse0 libc++-dev vdpau-va-driver libvulkan1</code></li> <li>GPU specific packages: <ul> <li>NVIDIA: <code>nvidia-opencl-icd nvidia-vdpau-driver nvidia-egl-icd nvidia-vulkan-icd libnvcuvid1 libnvidia-encode1</code></li> <li>Intel: <code>intel-media-va-driver i965-va-driver beignet-opencl-icd intel-opencl-icd</code></li> <li>AMD: <code>mesa-vdpau-drivers mesa-va-drivers mesa-opencl-icd libegl-mesa0 mesa-vulkan-drivers</code></li> </ul> </li> </ul> </li> <li>Android 6+</li> </ul>"},{"location":"guide/installation/#official-releases","title":"Official Releases","text":"<p>Prebuilt executables are available for Windows, Mac, and Linux. These can be found on the GitHub Releases</p>"},{"location":"guide/installation/#nightly-builds","title":"Nightly builds","text":"<p>In some cases you may need to download the latest nightly build:</p> <ul> <li>For example, a known bug was fixed in the nightly build and you need to use it urgently.</li> <li>Or, you want to see how the latest committed translation actually works in the app, Whether the translation needs to be fine-tuned to match the overall translation style.</li> </ul> <p>In general, however, we discourage casually trying nightly builds unless you know what you're doing!</p>"},{"location":"guide/installation/#build-local-version","title":"Build local version","text":"<p>For development purposes, a local version can be built. For the building instructions, see the development section on GitHub:</p>"},{"location":"guide/quickstart/","title":"Getting Started with Gyroflow 1.0 +","text":"<p>Welcome to the Gyroflow Quick Start Guide!</p> <p>Please use the Navigation Bar at the bottom of each page for a more step-by-step approach, or use the Navigation Menu on the left to get to a Hardware-specific Guide. Longer pages have a Table of Contents menu found on the right of the page.</p> <p>We hope these pages have been helpful and you enjoy using Gyroflow!</p> <p>Nurk FPV also made a nice tutorial for getting started with the software:</p>   <ol> <li>Download the executable corresponding to your system: https://github.com/gyroflow/gyroflow/releases</li> <li>Run the executable.</li> <li>Either open or drag your video file to Gyroflow.</li> <li>Lens profile and motion data files are automatically detected for some cameras (GoPros). Otherwise search for the correct lens profile and open the motion data file.</li> <li>Playback video to check if additional synchronization is required. If so, right-click on the timeline and select <code>Auto sync here</code> at at least two points of the video where some motion is present. This synchronises the gyro data and the video.</li> <li>Play with the stabilization options and algorithms. They all give different \"looks\" for the final result.</li> <li>Select output file settings and export.</li> </ol>"},{"location":"guide/settings/","title":"Settings Explanation","text":"<p>Gyroflow has a large number of settings for customizing everything. This page contains a short description and guide to each of the settings. Luckily, many of the settings are self-explanatory.</p> <p><p>Figure: Full screenshot</p></p>"},{"location":"guide/settings/#inputvideo-information","title":"Input/video information","text":"<p>After opening a video file, video information and metadata are displayed here.</p>"},{"location":"guide/settings/#frame-rate","title":"Frame rate","text":"<p>Set this value to the actual recording frame rate if it doesn't match the detected frame rate. This is the case for footage from some high speed cameras which play back in slow motion.</p>"},{"location":"guide/settings/#rotation","title":"Rotation","text":"<p>Modify the angle if unexpected video rotation is present (e.g. camera accidentally recording using portrait mode).</p>"},{"location":"guide/settings/#lens-profile","title":"Lens profile","text":"<p>Gyroflow requires correct lens profiles for undistortion and correctly applying the stabilization. For GoPro cameras, this is automatically detected based on the metadata. For other cameras, either search for the lens profile, or create a new profile (see the calibration guide).</p> <p>The lens profile is specific to a combination of a camera, a lens, a field of view, and the recording setting/aspect ratio. In general, it is best if the profile matches the setup exactly, but the same profile can be used if everything else matches except:</p> <ul> <li>Frame rate</li> <li>Resolution (with the same FOV and aspect ratio)</li> </ul> <p>This is the case since the lens distortion is independent from the framerate and is scaled to account for resolution differences.</p> <p>Lens profiles are stored as JSON files, which can be loaded without being part of the database.</p>"},{"location":"guide/settings/#motion-data","title":"Motion data","text":"<p>The motion data can either be embedded in the video file (GoPro/Insta360/Sony) or loaded as a separate motion data file (drone blackbox/Runcam/etc). Videos with embedded motion data can be treated as a motion data file as well, meaning an action camera like a GoPro can be mounted on a larger camera as a motion logger. The log detection and parsing uses telemetry-parser</p> <p>For more information about specific gyro logging methods, see pages under <code>Gyro Logging</code>.</p>"},{"location":"guide/settings/#low-pass-filter","title":"Low pass filter","text":"<p>Gyro data (especially from drones) can be noisy without filtering. Low pass filters essentially reduce frequencies above the cutoff frequency. If the gyro data appears too noisy, try enabling this filter with a cutoff of 50 Hz, with lower frequencies giving more filtering (more info here).</p>"},{"location":"guide/settings/#rotation_1","title":"Rotation","text":"<p>If the gyroscope sensor isn't aligned at right angles with the camera, an additional rotation can be applied here. For FPV users using blackbox data with a camera tilt, change the Pitch value to match the angle between the camera and the flight controller.</p>"},{"location":"guide/settings/#imu-orientation","title":"IMU Orientation","text":"<p>The compact <code>xyz</code> notation is used to describe the right-angle orientation between the camera and the gyro, with uppercase letters being positive and lowercase being negative. In most cases, this is automatically detected, but if stabilization appears to be applied in the wrong direction/axis, changing the IMU orientation may be required.</p> <p>If you have some <code>input</code> motion data, then <code>Yxz</code> means <code>output</code> (displayed in the graph) is computed as follows:</p> <ul> <li>Take <code>y</code> from <code>input</code> and put in <code>x</code> of <code>output</code></li> <li>Take <code>-x</code> from <code>input</code> and put in <code>y</code> of <code>output</code></li> <li>Take <code>-z</code> from <code>input</code> and put in <code>z</code> of <code>output</code></li> </ul>"},{"location":"guide/settings/#integration-method","title":"Integration method","text":"<p>For translating the raw gyroscope and accelerometer sensor readings to actual orientations usable for video stabilization, an integration method is used. Currently available are:</p> <ul> <li>None - Only applicable for cameras with pre-computed orientations (Hero 8 and newer)</li> <li>Madgwick filter</li> <li>Complementary filter</li> <li>Mahony filter</li> <li>Gyroflow integration</li> </ul> <p>Madgwick, Complementary, and Mahony all use a combination of gyroscope and accelerometer for estimating the orientation. The accelerometer allows for determining the downwards direction, meaning these integrators can be used with Lock horizon. With horizon lock, the Complementary filter usually gives decent results with the least horizon drift, but you can compare yourself. By comparison, the Gyroflow option only uses the gyroscope and doesn't work with horizon leveling.</p> <p>For hero 8 and newer, selecting None means no synchronization is required at all.</p>"},{"location":"guide/settings/#synchronization","title":"Synchronization","text":"<p>Synchronization is typically required between the video and and gyro data. This can either be auto-sync, or by manually syncing at specified times by right-clicking the timeline. </p>"},{"location":"guide/settings/#rough-gyro-offset","title":"Rough gyro offset","text":"<p>If a significant delay is present between the start of the video recording and gyro recording, the rough gyro offset needs to be changed. Example: if you start video recording followed by gyro recording 30 seconds later, use 30 s here.</p>"},{"location":"guide/settings/#sync-search-size","title":"Sync search size","text":"<p>Gyroflow analyzes a segment of the video, and attempts to find the most likely match within this search size in order to avoid false positives.</p>"},{"location":"guide/settings/#max-sync-points","title":"Max sync points","text":"<p>Number of automatically added sync points.</p>"},{"location":"guide/settings/#analyze-every-n-th-frame","title":"Analyze every n-th frame","text":"<p>This is typically left unchanged. By setting this to a number larger than 1, frames are skipped during the motion analysis. One use case is high framerate footage, where the relative motion between two subsequent frames is too small for reliable sync.</p>"},{"location":"guide/settings/#time-to-analyze-per-sync-point","title":"Time to analyze per sync point","text":"<p>Determines the number of frames analyzed analyzed for each sync point. More frames take slightly longer, but may give a better sync. The default is typically fine.</p>"},{"location":"guide/settings/#optical-flow-method","title":"Optical flow method","text":"<p>Select the optical flow implementation. Either OpenCV (typically faster and preferred) or AKAZE.</p>"},{"location":"guide/settings/#offset-calculation-method","title":"Offset calculation method","text":"<p>This is the method used to estimate the gyro-video offset.</p> <ul> <li>Using essential matrix - Estimate relative roll/pitch/yaw angular rates between each frame, and correlate with gyro sensor data.</li> <li>Using visual features - Estimate the gyro offset such that the tracked features move the least between frames.</li> </ul>"},{"location":"guide/settings/#low-pass-filter_1","title":"Low pass filter","text":"<p>Apply a low pass filter to the estimated video motion. This is rarely needed.</p>"},{"location":"guide/settings/#show-detected-features-show-optical-flow","title":"Show detected features / Show optical flow","text":"<p>Shows the motion in the video player during playback</p>"},{"location":"guide/settings/#stabilization","title":"Stabilization","text":"<p>This is an exciting menu: The actual video stabilization! In general, try playing with the different stabilization algorithms. Each result in a different \"look\" for the stabilized video. If you're interested in developing your own stabilization algorithm, take a look here. </p>"},{"location":"guide/settings/#fov","title":"FOV","text":"<p>Apply a scale to the field of view of the output video.</p>"},{"location":"guide/settings/#stabilization-algorithm","title":"Stabilization algorithm","text":"<p>The currently available stabilization algorithms are:</p> <ul> <li>No smoothing - Useful if only lens undistortion is desired</li> <li>Plain 3D - Simple general purpose smoothing algorithm described here. Smoothing applied symmetrically in 3D with no rotation limit (doesn't work for rapid camera motion).</li> <li>Velocity dampened - Decreases the smoothing during significant camera motion in order to avoid the image moving out of frame.</li> <li>Velocity dampened per axis - Similar to Velocity dampened with individual roll/pitch/yaw smoothness control. Typically the roll axis can be smoothed out more.</li> <li>Lock horizon - Attempts to keep the horizon level. Works best for flight without fast rotational moves since some gyros can be maxed out. Try with the complementary filter.</li> <li>Fixed camera - Points the virtual camera in a fixed, used-defined direction. Can be useful for debugging or tweaking sync.</li> </ul>"},{"location":"guide/settings/#crop","title":"Crop","text":"<p>Select the behavior of the cropping.</p> <ul> <li>No cropping - Remain at the user-defined FOV throughout the video</li> <li>Dynamic cropping - Dynamically adjust the field of view in order to hide any borders throughout the video. The <code>Smoothing window</code> influences how quickly the FOV changes in response to different stabilized frame orientations.</li> <li>Static crop - Static crop with FOV=1 being the FOV at which no edges are visible throughout the video.</li> </ul>"},{"location":"guide/settings/#rolling-shutter-correction","title":"Rolling shutter correction","text":"<p>Rolling shutter artifacts are visible during fast camera motion, and appears as \"wobbling\" or skewed lines. This option requires precise gyro-video sync. Find a spot in the video with clear rolling shutter artifacts, and adjust the frame readout time until these artifacts are minimized. By default, the frame readout is assumed to be from top to bottom. This is changed with the checkbox.</p> <p>The readout time can also be estimated with the \"Estimate rolling shutter here\" option in the context menu of the timeline, although this is experimental.</p>"},{"location":"guide/settings/#export","title":"Export","text":"<p>The options here are fairly self-explanatory. For any doubts, see the tooltips. By default, the resolution and bitrate are selected to correspond closely to the input file </p> <p>From the dropdown of the export button, it is possible to export a <code>.gyroflow</code>. This file contains all the required data and sync information for a video file, and is automatically detected the next time you want to process the same file.</p>"},{"location":"guide/synchronization/","title":"Synchronization","text":"<p>This page describes the gyro-video synchronization process in more detail. In a lot of cases, automatic sync works out of the box, so this is only required for tricky scenarios.</p>"},{"location":"guide/workflow/","title":"General Workflows","text":"<p>This page contains several common minimal workflows for stabilizing video with Gyroflow.</p>"},{"location":"guide/workflow/#cameras-w-motion-data","title":"Cameras w/ Motion Data","text":"<p>It is relatively simple to use a camera that can directly output gyro data in the machine, just drag and drop the video file (and gyro log) to gyroflow.</p>"},{"location":"guide/workflow/#cameras-without-motion-data","title":"Cameras without Motion Data","text":"<p>The use of the camera that cannot directly output the gyro data in the machine is more flexible. The video file and the gyro log are from different devices, and the two parts need to be manually added to gyroflow.</p>"},{"location":"guide/workflow/#action-as-logger","title":"Action as logger","text":""},{"location":"guide/workflow/#fc-as-logger","title":"FC as logger","text":""},{"location":"integrations/integrations/","title":"List of tools","text":"<p>This page contains tools or projects designed to work with Gyroflow.</p>"},{"location":"integrations/integrations/#gyroflow-openfx","title":"Gyroflow OpenFX","text":"<p>The Gyroflow OpenFX plugin allows for applying stabilization using a <code>.gyroflow</code> file to a video directly in a video editor such as Davinci Resolve. This allows for stabilizing RAW and specialised video formats. This plugin is under development by Ilya Epifanov. Downloads and instructions can be found on the GitHub Repository:</p> <p>gyroflow-ofx</p>"},{"location":"integrations/integrations/#gyroflow-to-csv","title":"Gyroflow to CSV","text":"<p>Gyroflow to CSV by EmberLightVFX can convert Gyroflow project files to a CSV format containing the camera motion. This can be imported in software such as Blackmagic Fusion and may be used for VFX work.</p> <p>Gyroflow to CSV</p>"},{"location":"integrations/integrations/#gyroflow-toolbox","title":"Gyroflow Toolbox","text":"<p>Gyroflow Toolbox by latenitefilms allows you to import Gyroflow Projects directly into Apple's Final Cut Pro.</p> <p>Gyroflow Toolbox</p>"},{"location":"logging/actioncamlogger/","title":"Action cam as logger","text":"<p>Due to the flexibility of Gyroflow, the gyro source and the video source can be \"mismatched\". This means that an action camera with internal gyro logging (e.g. GoPro) can be mounted to a high-end cinema camera acting as a gyro logger. This setup is illustrated below.</p>  <p>The advantages of this setup is the availability of GoPros/Insta360 cameras among filmmakers, meaning no additional hardware other than some fasteners.</p> <p>With this setup, a number of things should be considered:</p> <ul> <li>The cinema camera and logger camera should be rigidly attached to each other to avoid mismatching motion data.</li> <li>The two should ideally be oriented in the same direction to avoid additional angle corrections.</li> <li>Starting recording of the two cameras at almost the same time, or with a small fixed offset (e.g. 10 seconds) makes synchronization easier.</li> </ul> <p>This setup has successfully been used with GoPro Hero 6/8/9, the Insta360 OneR/Go 2 among others. In general, any camera with gyro logging should work, assuming the gyro data is clean and correct.</p> <p>When using a GoPro hero 8 or newer as a gyro logger, the internally computed orientations (<code>None</code> integration method) should not be used, since these orientations only correspond to each frame from the GoPro file.</p>"},{"location":"logging/betaflight/","title":"Betaflight/INav/Cleanflight/etc.","text":"<p>Betaflight/Cleanflight/Inav/Emuflight/etc form a popular family of flight control firmware for high-performance multicopters. By using the built-in blackbox logging feature, gyro data for use with Gyroflow video stabilization can be collected. This was in fact one of the initial goals of the project! Betaflight, Cleanflight, Inav, Emuflight etc. all use more or less the same structure for handling blackbox data logging, so this page covers all of these.</p>"},{"location":"logging/betaflight/#hardware","title":"Hardware","text":"<p>As you may already know, the above mentioned flight firmwares can all run on the same type of hardware. A flight controller supporting this family of flight firmwares typically contain:</p> <ul> <li>STMicroelectronics 32 bit microcontroller (F4, F7, G4, H7)</li> <li>MEMS inertial measurement unit (MPU6000, BMI270, ICM2xxxx, ICM4xxxx etc.)</li> </ul> <p>Some flight controllers have an onboard magnetometer. In general, this is not required for video stabilization purposes unless absolute orientation is desired.</p> <p>Different gyros exhibit different behaviors in terms of data quality, noise, etc. In general, if the IMU is capable of providing clean data for the drone control loop, the same data is suitable for video stabilization purposes.</p> <p>For blackbox data logging, the hardware typically either contains an onboard SPI Flash chip, or a slot for an SD card. If neither of these are available, additional hardware solutions can be connected to the flight controller in order to enable blackbox logging. This can be using:</p> <ul> <li>The Openlager - A open source and commercially available board containing an STM32f4 and a MicroSD slot for logging high rate data through a spare serial port.</li> <li>Tiny Blackbox - An open source ultra-light logger containing a 16 MB flash chip.</li> <li>SparkFun OpenLog - A serial-based logger similar to the Openlager. This is no longer officially supported by Betaflight etc. due to data rate limitations. </li> </ul>"},{"location":"logging/betaflight/#betaflightcleanflightemuflight","title":"Betaflight/(Cleanflight/Emuflight?)","text":"<p>Required software:</p> <ul> <li>Betaflight/Cleanflight/Emuflight configurator</li> <li>Betaflight blackbox explorer</li> </ul> <p>The following should be a decent starting point for the blackbox configuration</p> <ul> <li>250 Hz logging rate</li> <li>Debug mode: <code>None</code></li> </ul> <p>If you're running Betaflight 4.3 or newer, it is possible to deselect specific elements of the data logging in order to save precious recording space.</p>"},{"location":"logging/betaflight/#gyroflow-logger-preset","title":"Gyroflow logger preset","text":"<p>We have a gyroflow-betaflight presets source for your convenience. You can easily set it up like the picture shown below:</p>  <p>Once the gyroflow logger preset is actived, you'll see some special gyroflow presets:</p> <ul> <li>Gyroflow minimal settings: for users who wanna use the blackbox data from main FC as motion data for video stabilization.</li> <li>Sencondary FC as Gyroflow motion logger: for users who use a secondary FC as a gyroflow motion logger.</li> <li>Gyroflow BMI270 Filter sttings: for users whose FC has a BMI270 sensor and want to use it as a gyroflow motion logger.</li> <li>Flowbox target settings: preset for flowbox and flowbox+flowshutter</li> </ul>"},{"location":"logging/betaflight/#cli-commands","title":"CLI commands","text":"<p>Or you might prefer the \"old fashion\", from the CLI: <pre><code>set blackbox_disable_pids = ON\nset blackbox_disable_rc = ON\nset blackbox_disable_setpoint = ON\nset blackbox_disable_bat = ON\nset blackbox_disable_mag = ON\nset blackbox_disable_alt = ON\nset blackbox_disable_rssi = ON\nset blackbox_disable_debug = ON\nset blackbox_disable_motors = ON\nset blackbox_disable_gps = ON\n</code></pre></p> <p><p>Betaflight configurator blackbox tab</p></p>"},{"location":"logging/betaflight/#acknowledgements","title":"Acknowledgements","text":"<ul> <li>logger-presets: Forked from betaflight/firmware-persets</li> </ul>"},{"location":"logging/customlogger/","title":"Custom and DIY hardware logging","text":"<p>This page contains an example of how data logging can be implemented and existing projects you can build and/or adapt.</p>"},{"location":"logging/customlogger/#existing-diy-options","title":"Existing DIY options","text":""},{"location":"logging/customlogger/#esplog-by-vladimirp1","title":"esplog by VladimirP1","text":"<p>A ESP32-based motion data logger with wireless control and data transfer. Available as a small breakout board version or a tiny single PCB version. The developer and testers of esplog can be found on the Gyroflow discord.</p>  <p>esplog on Github</p>"},{"location":"logging/customlogger/#flowshutter-and-flowbox-by-dusking1","title":"Flowshutter and Flowbox by Dusking1","text":"<p>These are motion data loggers developed by Dusking1 using the Betaflight firmware. The Flowshutter is designed to be capable of triggering a variety of cameras for a one-click operation.</p> <p>Flowshutter on Github</p>"},{"location":"logging/customlogger/#hardware","title":"Hardware","text":"<p>An MEMS Inertial Measurement Unit (MEMS IMU) is a chip containing a gyroscope and an accelerometer. The gyroscope measures the rotational rate, while the accelerometer measures acceleration as the name implies. Gyroflow requires the gyroscope, while the accelerometer is optional and only required if horizon referencing is desired. An example of the acceleration and rotational axes around a camera is illustrated above. Many camera systems already contain such an IMU for electronic image stabilization, so in some cases, it is possible to allow for motion logging through a firmware update.</p> <p>For a dedicated logger, a simple combination of a memory device (MicroSD/SPI Flash chip etc.), a microcontroller, and an inertial measurement unit suffices. This hardware combination is readily available as low-cost drone flight controllers, which can act as loggers as described on another page.</p> <p>For arduino and embedded electronics hobbyists, this is a fairly basic project that can be built on a breadboard/perfboard </p>"},{"location":"logging/customlogger/#softwarefirmware","title":"Software/Firmware","text":"<p>On the software and firmware side, the inertial measurement unit should be configured correctly. Refer to the datasheet of your IMU for information about how to configure this exactly. It has been found that the following IMU settings offer a reasonable starting point.</p> <ul> <li>logging rate: 500 Hz</li> <li>Low pass filter cutoff: 50 to 100 Hz</li> <li>gyro scaling: 1000 deg/s</li> <li>acceleration scaling: +/- 8 g</li> </ul> <p>The minimum logging rate sufficient for stabilization is approximately 100 Hz, but note that such a low logging rate requires excellent filtering in order to avoid data loss and aliasing. Using a 500 Hz logging rate with a 100 Hz cutoff allows for some margin of error in terms of aliasing.</p>"},{"location":"logging/customlogger/#logging","title":"Logging","text":"<p>Logging of Gyroscope, and optionally, Accelerometer and Magnetometer can be in various formats. The <code>.gcsv</code> log format described here is a simple to implement format suitable for basic motion loggers.</p>"},{"location":"logging/flowbox/","title":"Flowbox","text":"<p>Flowbox is an extremely compact gyro logger developed for using with Gyroflow. It has:</p> <ul> <li>USB-C connector</li> <li>STM32F411 MCU</li> <li>BMI270 IMU</li> <li>128MB onboard SPI flash chip</li> <li>Onboard beeper</li> <li>2 UARTs</li> </ul> <p>It is not yet available, but here's basic tutorial.</p>"},{"location":"logging/flowbox/#start-with-presets","title":"Start with presets","text":"<p>Since the flowbox is based on F411 MCU and BMI270 gyroscope, only betaflight 4.3 or newer firmware support it.</p> <p>We have a gyroflow-betaflight presets source for your convenience, and you can quickly set up your flowbox with \"one click\".</p> <p>Gyroflow-betaflight preset source can be easily set up followed the picture shown below:</p>  <pre><code>https://github.com/gyroflow/logger-presets\n</code></pre>"},{"location":"logging/flowbox/#tranditional-setup-procedure","title":"Tranditional setup procedure","text":""},{"location":"logging/flowbox/#flash-firmware","title":"Flash firmware","text":"<p>The flashing procedure is pretty similar to other betaflight flight controllers. here's the step:</p> <ol> <li>Connect your flowbox to your computer.</li> <li>Open the latest betaflight configurator (version 10.8.0 or newer).</li> <li>Open \"Firmware Flasher\", search and choose \"flowbox\" in the target selector</li> <li>Select 4.3.0 or newer firmware version.</li> <li>Hit the \"Load Firmware [Online]\" button, then later hit the \"Flash Firmware\" button. </li> <li>Once the flashing progress is done, try to connect. The configurator will ask you whether apply the custom default. Click \"Apply Custom Default\" button. </li> <li>Then reconnect, whola!</li> </ol>"},{"location":"logging/flowbox/#settings","title":"Settings","text":"<p>It is recommended to use a single PT3 @80Hz on gyroscope data for this application usage. Also, the dynamic notch filter could be quite useful for hard mounted, but this would request to config the motor protocol to be Dshot300.</p> <p><pre><code>feature DYNAMIC_FILTER\nset runaway_takeoff_prevention = OFF\nset pid_process_denom = 1\nset motor_pwm_protocol = DSHOT300\nset simplified_gyro_filter = OFF\nset gyro_lpf1_static_hz = 0\nset gyro_lpf2_type = PT3\nset gyro_lpf2_static_hz = 80\nset gyro_lpf1_dyn_min_hz = 0\nset gyro_lpf1_dyn_max_hz = 0\nset simplified_gyro_filter = OFF\n</code></pre> This can also be done in GUI, but CLI command is easy and no bias.</p>"},{"location":"logging/flowbox/#logging-trace","title":"Logging trace","text":"<p>Since flowbox was used as a secondary FC which only the gyro data is need, we can simply disable other \"useless\" log traces in order to save flash space and reduce log size. <pre><code>set blackbox_sample_rate = 1/16\nset blackbox_disable_pids = ON\nset blackbox_disable_rc = ON\nset blackbox_disable_setpoint = ON\nset blackbox_disable_bat = ON\nset blackbox_disable_mag = ON\nset blackbox_disable_alt = ON\nset blackbox_disable_rssi = ON\nset blackbox_disable_acc = ON\nset blackbox_disable_debug = ON\nset blackbox_disable_motors = ON\nset blackbox_disable_gps = ON\n</code></pre></p> <p>If you want to use gyroflow's \"horizon lock\" features: <pre><code>set blackbox_disable_acc = OFF\n</code></pre></p>"},{"location":"logging/flowbox/#board-orientation","title":"Board orientation","text":"<p>Based on your mounting, you should change the board orientation so for the board can record the correct motion data.</p>"},{"location":"logging/flowbox/#trigger-the-recording","title":"Trigger the recording","text":"<p>There are many ways to trigger the blackbox record, here we simply show you the mostly common used two ways.</p> <ul> <li>Triggered by receiver</li> <li>No trigger, record blackbox data automatically when power up</li> </ul>"},{"location":"logging/flowbox/#by-receiver","title":"By receiver","text":"<p>Betaflight can record blackbox when the FC was ARMed. So you need to hook a serial receiver to a UART and set it up properly in betaflight configurator.</p> <p>Flowbox has two UARTs, which support a lot of serial receiver (not included SBUS protocol) include CRSF, iBUS, SRXL, etc. The pads are shown as below:</p>  <p>Once the receiver is hooked up, you need to set the correspond UART and protocol.</p>"},{"location":"logging/flowbox/#no-trigger","title":"No trigger","text":"<p>Betaflight can also record blackbox when the FC was powered up. Simply set the <code>blackbox_mode = ALWAYS</code></p> <pre><code>set blackbox_mode = ALWAYS\n</code></pre>"},{"location":"logging/flowbox/#use-with-flowshutter","title":"Use with flowshutter","text":"<p>Check flowshutter</p>"},{"location":"logging/flowshutter/","title":"Flowshutter","text":"<p>Flowshutter is a custom camera remote. When used in conjunction with readily available hardware, this results in a flexible and reliable external camera motion logger for Gyroflow. It can provide precise synchronization of camera video recording and motion logger (betaflight/emuflight FC) recording.</p> <p>It was designed to be used with the Gyroflow software to provide you one of the best open source video stabilization experiences.</p>"},{"location":"logging/gbin/","title":"Gbin","text":"<p>Warning</p> <p>This reference is not complete and should not currently be followed</p>  <p>On the previous page, the <code>.gcsv</code> format was described. The text-based CSV file has the advantage of being easily formatted and human-read, but the disadvantage of taking up significantly more space that what is required for just the raw data. For instance, a 16-bit or two byte number may take up around 7 bytes due to each decimal being one byte. For this reason, this page describes an alternative format dubbed <code>.gbin</code>. This is a binary format and thus significantly more compared than the <code>.gcsv</code> format.</p>"},{"location":"logging/gbin/#header","title":"Header","text":"<p>In order to allow for easy identification of the main parameters without decoding the file, the same ASCII header as the <code>.gcsv</code> format is used.</p> <pre><code>GYROFLOW GBIN LOG\nversion,1.1\nid,custom_logger_name\norientation,YxZ\nnote,development_test\nfwversion,FIRMWARE_0.1.0\ntimestamp,1644159993\nvendor,potatocam\nvideofilename,videofilename.mp4\nlensprofile,potatocam_mark1_prime_7_5mm_4k\ntscale,0.001\ngscale,0.00122173047\nascale,0.00048828125\nDATA:\nt,gx,gy,gz,ax,ay,az\n0,39,86,183,-1137,-15689,-2986\n1,56,100,202,-1179,-15694,-2887\n2,63,108,218,-1247,-15702,-2794\n3,71,108,243,-1308,-15675,-2727\n4,83,101,268,-1420,-15662,-2661\n</code></pre> <p>The next is the data: <pre><code>[0xAA][32-bit uint32 time][3x int16][3x int16][3x int16]\n</code></pre></p> <p>Behavior of the parser: Start reading, when done, check if the separator is present. </p>"},{"location":"logging/gcsv/","title":"Gyroflow .gcsv reference","text":""},{"location":"logging/gcsv/#gcsv-gyro-log-format","title":"<code>.gcsv</code> gyro log format","text":"<p>What follows is a text-based gyro log format that can be implemented in custom hardware/firmware called <code>.gcsv</code> (short for gyro csv or Gyroflow csv). As a text-based format this is meant to be easily implementable and inspectable (compatible with standard CSV reading software) at the cost of space efficiency.</p> <p>Firstly, for a video file called <code>videofilename.mp4</code>, the corresponding gyro log file is <code>videofilename.gcsv</code>, this is a case of the <code>.gcsv</code> acting as sidecar files. This allows for automatic log detection.</p> <p>The <code>.gcsv</code> file contains information about the gyro orientation, scaling, and a unique identifier. The following is an example of a .gcsv file from a logger supporting logging of gyro and accelerometer:</p> <p><pre><code>GYROFLOW IMU LOG\nversion,1.3\nid,custom_logger_name\norientation,YxZ\nnote,development_test\nfwversion,FIRMWARE_0.1.0\ntimestamp,1644159993\nvendor,potatocam\nvideofilename,videofilename.mp4\nlensprofile,potatocam/potatocam_mark1_prime_7_5mm_4k\nlens_info,wide\nframe_readout_time,15.23\nframe_readout_direction,0\ntscale,0.001\ngscale,0.00122173047\nascale,0.00048828125\nt,gx,gy,gz,ax,ay,az\n0,39,86,183,-1137,-15689,-2986\n1,56,100,202,-1179,-15694,-2887\n2,63,108,218,-1247,-15702,-2794\n3,71,108,243,-1308,-15675,-2727\n4,83,101,268,-1420,-15662,-2661\n5,101,93,294,-1575,-15661,-2629\n6,121,95,319,-1677,-15654,-2639\n7,143,97,348,-1709,-15673,-2654\n8,163,98,362,-1704,-15691,-2685\n9,173,93,371,-1678,-15698,-2736\n10,181,98,375,-1623,-15697,-2810\n11,173,105,365,-1578,-15693,-2929\n12,159,111,363,-1555,-15711,-3057\n13,157,113,348,-1540,-15747,-3159\n14,157,118,327,-1542,-15780,-3246\n15,153,123,310,-1595,-15812,-3319\n...\n</code></pre> If a magnetometer is present, some additional fields are present, e.g.: <pre><code>GYROFLOW IMU LOG\nversion,1.3\nid,custom_logger_name\norientation,YxZ\nnote,development_test\nfwversion,FIRMWARE_0.1.0\ntimestamp,1644159993\nvendor,potatocam\nvideofilename,videofilename.mp4\nlensprofile,potatocam_mark1_prime_7_5mm_4k\ntscale,0.001\ngscale,0.00122173047\nascale,0.00048828125\nmscale,0.00059875488\nt,gx,gy,gz,ax,ay,az,mx,my,mz\n0,39,86,183,-1137,-15689,-2986,123,345,546\n1,56,100,202,-1179,-15694,-2887,124,344,560\n...\n</code></pre></p>"},{"location":"logging/gcsv/#mandatory-fields","title":"Mandatory fields:","text":"<ol> <li>The very first line identifies the file as an IMU log. This line should either be <code>GYROFLOW IMU LOG</code> or the more neutral <code>CAMERA IMU LOG</code>.</li> <li>The second line <code>version,1.3</code> describes the \"version\" of the .gcsv file format. This is equal to <code>1.3</code> for now. The versions are backwards compatible, but changes with the addition of new metadata fields.</li> <li>The third line contains a unique ID associated with the logger/camera. For instance a high-end camera with internal logging may use <code>id,potatocam_deluxe_4k_grey_edition</code>.</li> <li>The fourth line contains the orientation string. This corresponds to the <code>IMU Orientation</code> field in Gyroflow (see the implementation notes below for further details).</li> <li>The next few lines contain optional metadata. These are not strictly required, but may improve workflow and stabilization. Developers are thus encouraged to include all known fields.</li> <li>The subsequent lines with <code>tscale</code>, <code>ascale</code> and <code>gscale</code> describe constants used to scale the raw sensor values.<ul> <li>Multiplying <code>tscale</code> by the raw <code>t</code> values should give the time in seconds. It can thus be deduced that the file above is logging at 1000 Hz since each line increments by <code>1*0.001=0.001 s</code>, corresponding to a frequency of 1 KHz. The resolution of the timestamps should be 1 ms or better.</li> <li>Multiplying <code>gscale</code> by the raw <code>gx/gy/gz</code> values should give the angular rate in rad/s</li> <li>(If accelerometer data present) Multiplying <code>ascale</code> by the raw <code>ax/ay/az</code> values should give the acceleration in g</li> <li>(If magnetometer data present) Multiplying <code>mscale</code> by <code>mx/my/mz</code> gives the measurements in gauss (Note that <code>1 tesla = 10000 gauss</code>).</li> </ul> </li> <li>The rest of the file simply consists of a standard CSV header and the raw values. The header and data order should be one of the following: <code>t,gx,gy,gz</code>, <code>t,gx,gy,gz,ax,ay,az</code>, or <code>t,gx,gy,gz,ax,ay,az,mx,my,mz</code>. Gyroscope data is the minimum requirement. Acceleration data is required for horizon lock, while magnetometer data improves drift in orientation determination (Not currently of significant importance).</li> <li>For the data itself, fixed-point integers are recommended with a scalar (point 6) in order to avoid excessively large text files. Using floating points here is still valid though. </li> </ol>"},{"location":"logging/gcsv/#optional-fields","title":"Optional fields:","text":"<p>The following are all optional fields for the metadata block, but developers should include as many known fields as possible.</p> <ul> <li><code>Note</code> is for other misc. information.</li> <li><code>fwversion</code> is the firmware of the logger/camera.</li> <li><code>timestamp</code> is the unix timestamp when logging began.</li> <li><code>vendor</code> can contain the vendor or developer</li> <li><code>videofilename</code> is the name of the corresponding video file. Normally the <code>.gcsv</code> file name already matches, but this insures the information is kept if the filename changes.</li> <li><code>lensprofile</code> is the unique name of the lens preset and vendor folder. If it matches a lens profile in the database it is automatically selected during loading.</li> <li><code>lens_info</code> is additional information about the lens/field of view not available in the metadata. This could be <code>wide</code>, <code>normal</code>, <code>narrow</code> for different FOV settings, <code>linear</code> for lens distortion correction. Most relevant for action cameras with different crop settings.</li> <li><code>frame_readout_time</code> is the time in milliseconds it takes to capture a full video frame using rolling shutter. This is used for rolling shutter correction.</li> <li><code>frame_readout_direction</code> is the direction of the readout. Most cameras with rolling shutter capture the top of the frame first. Note that Gyroflow currently only supports correcting 0 and 1.<ul> <li>0: Top to bottom</li> <li>1: Bottom to top</li> <li>2: Left to right</li> <li>3: Right to left</li> </ul> </li> </ul>"},{"location":"logging/gcsv/#implementation-notes","title":"Implementation notes","text":"<p>The required parts of the header of the <code>.gcsv</code> file remains static for a given camera/setup, and can thus be written as a constant string to the file.</p> <p>Raw sensor values are often represented as 16-bit signed integers, meaning a range between of <code>+/- 2^15</code>. If the acceleration range is known to be +/- 4 g as was the case in the example above. Then <code>ascale = 4/2^15 = 0.00012207031</code>. Refer to the datasheet for conversion information. Similarly, a gyroscope with a range of <code>+/- 1000 deg/s</code> gives <code>gscale = (1000 * pi / 180)/2^15 = 0.00053263221</code>. Note that even when configured to a setting such as <code>+/- 1000 deg/s</code>, the actual calibration of the sensor may lead to a maximum slightly above or below this value. As always, consult the datasheet.</p> <p>For a logger/camera implementation, some other things to think about:</p> <ul> <li>For a camera, the timestamps should be based on the same time source as the video capture. This prevents drift between the two.</li> <li>Consider using microseconds for the timestamp if a faster sampling rate if the time source allows. This may improve the timing during the sync process.</li> <li>Consider using the data ready interrupts of IMU's instead of polling for more consistent timings.</li> <li>Ensure proper filtering of the data to meet the Nyquist criteria for the samling frequency. Even more filtering is usually recommended, e.g. setting the builtin hardware low pass filter cutoff at 50 Hz to 100 Hz is a good starting point, even for higher sampling frequencies.</li> </ul> <p>For the IMU Orientation string, the following figure corresponds to <code>YxZ</code>.</p>  <ul> <li>For the gyroscope, data for an axis correspond to the right-handed rotation rate of the camera body about that axis.</li> <li>The accelerometer data correspond to linear acceleration applied in the given direction. Due to the nature of gravity, a stationary object will experience an upwards acceleration of 9.81 m/s2, while an object in freefall will experience zero acceleration.</li> <li>The magnetometer data corresponds to the measured magnetic field vector.</li> </ul> <p>In order for orientation determination to work correctly, the data must have the same/aligned coordinate axes. For combined IMU sensors, this is already the case for the raw data. If a rotation is applied to the gyro data before being written, the same rotation should be applied to the accelerometer (and magnetometer). This ensures that the axes stay aligned.</p> <p>If the gyroscope and accelerometer data come from separate sensors, their axes must similarly be aligned, either physically or by applying a rotation in software.</p>"},{"location":"logging/gcsv/#version-changelog","title":"Version changelog","text":"<ul> <li>1.0: Initial version</li> <li>1.1: Add lens profile field</li> <li>1.2: Add rolling shutter information</li> <li>1.3: Add <code>lens_info</code> field</li> </ul>"},{"location":"logging/general/","title":"General","text":"<p>Gyroflow needs a source of gyroscope data (and optionally accelerometer data) to operate. Currently, Gyroflow supports the following gyro log types:</p>"},{"location":"logging/general/#supported-formats","title":"Supported formats:","text":"<ul> <li>GoPro (All models with gyro metadata, starting with HERO 5)</li> <li>Sony (a1, a7c, a7r IV, a7 IV, a7s III, a9 II, FX3, FX6, RX0 II, RX100 VII, ZV1, ZV-E10)</li> <li>Insta360 (OneR, SMO 4k, GO2)</li> <li>Betaflight blackbox (CSV and binary)</li> <li>Runcam CSV (Runcam 5 Orange, iFlight GOCam GR)</li> <li>Hawkeye Firefly X Lite CSV</li> <li>WitMotion (WT901SDCL binary and *.txt)</li> <li>Mobile apps: <code>Sensor Logger</code>, <code>G-Field Recorder</code>, <code>Gyro</code></li> <li>Gyroflow .gcsv log</li> <li>ArduPilot VideoStabilization logging (*.log)</li> <li>(TODO) DJI flight logs (.dat, .txt)</li> </ul> <p>The subsequent pages will contain information about specific logging methods.</p>"},{"location":"logging/orientation/","title":"Orientation","text":"<p>In order to find the IMU orientation, the following approach can be used. Essentially, by moving the system in a known order, the observed gyro/accelerometer signal can be compared to teh <code>correct</code> one.</p> <p>Firstly, the \"standard\" Gyroflow input orientation is defined as follows. Suppose a camera is pointed with the lens forwards in a horizontal orientation. The z vector is then pointed backwards, the x vector pointed upwards, and the y vector pointed to the left. This is illustrated in the figure below.</p> <p>The measured accelerations and angular rates are assumed to be aligned.</p>"},{"location":"logging/orientation/#find-orientation-for-existing-footage","title":"Find orientation for existing footage","text":"<p>If you have captured footage with an unknown orientation, it is also possible to deduce the correct orientation based on the video and gyro data. </p>"},{"location":"tech/filtering/","title":"Filtering and noise","text":"<p>For video stabilization, logging rates of at least 100 Hz of clean data has shown to work, with clean being the keyword. This page contains some info about the quality of the gyro data.</p>"},{"location":"tech/filtering/#aliasing","title":"Aliasing","text":"<p>For number one, adequate filtering should be applied before the saving step in order to satisfy the Nyquist\u2013Shannon sampling theorem. This may sound fancy, but just means the frequencies in the signal should be limited to at most, half the sampling frequency. For a 200 Hz logging rate, a low pass/decimation filter with a cutoff of about 100 Hz should be applied. Most MEMS gyroscopes contain on-board options for low pass filtering, but depending on the exact chip, this may not be adequate for handling harsh vibration-heavy environments on a drone.</p>"},{"location":"tech/filtering/#gyro-camera-coupling","title":"Gyro-camera coupling","text":"<p>The physical gyro should match the motion of the camera, meaning no or minimal play should be present between the two. This is not a problem for built-in gyro logging case.</p>"},{"location":"tech/filtering/#filtering","title":"Filtering","text":"<p>If no aliasing is present, the gyro data can be further filtered, assuming the sampling rate is sufficiently high. Roughly speaking, the frequencies of camera shake lie below 50 Hz. Frequencies above this could either be noise or high frequency signals resulting from high frequency, but low amplitude vibrations. </p>"},{"location":"tech/relatedprojects/","title":"Related Projects/Literature","text":"<p>This page contains projects and technical literature which may be of interest to those wanting to learn more about gyro-based video stabilization.</p>"},{"location":"tech/relatedprojects/#gyro-assisted-video-stabilization-projects","title":"Gyro-assisted video stabilization projects","text":"<ul> <li>Legacy Python-version of Gyroflow</li> <li>Virtual Gimbal by Yoshiaki Sato. Another gyro-assisted stabilization tool</li> <li>Video-Stabilization by Alex Karpenko. One of the first implementations of the method</li> </ul>"},{"location":"tech/relatedprojects/#papers","title":"Papers","text":"<ul> <li>Digital Video Stabilization and Rolling Shutter Correction using Gyroscopes - 2011 paper describing gyro-assisted video stabilization</li> <li>Animating Rotation with Quaternion Curves - Describes SLERP, used for orientation smoothing in Gyroflow</li> <li>A Generic Camera Model and Calibration Method for Conventional, Wide-Angle, and Fish-Eye Lenses - the default lens model used in Gyroflow</li> <li>Online Gyroscope-Camera Autocalibration for Image Enhancement on Smartphones - Master Thesis about gyro-assisted video stabilization</li> </ul>"},{"location":"tech/rollingshutter/","title":"Rolling Shutter","text":"<p>Rolling shutter artifacts are caused by camera sensors reading lines sequentially instead of simultaneously (global shutter). With the correct settings, Gyroflow is capable of correcting for rolling shutter artifacts.</p>"},{"location":"tech/rollingshutter/#frame-readout-time-determination","title":"Frame readout time determination","text":"<p>There are multiple ways of determining the frame readout time. One approach is by recording a rapidly flashing source of light with a known frequency or pulse width, and analyzing the resulting image. For a known pulse width, the size of the bands can be used in order to find the frame readout time. For a known frequency, the number of bands can be counted. Using LED's for rolling shutter measurements is described in this blog post: https://joancharmant.com/blog/measuring-rolling-shutter-with-a-strobing-led/</p>"},{"location":"tech/smoothing/","title":"Orientations and smoothing","text":"<p>In order to stabilize the orientation, a smoothing algorithm is used. This is in essence a low pass filter applied to the 3D orientation. To illustrate how this works, let's take one of the simplest low pass filters in 1D: the exponential filter, also known as exponential moving average or exponentially weighted moving average depending on the field of study (see the wikipedia article for more info). If \\(\\alpha\\) be a number between 0 and 1 and the \\(Y_t\\) being the t-th input sample. The output, \\(S_t\\) of this low pass filter is then:</p> \\[ {\\displaystyle S_{t}={\\begin{cases}Y_{1},&amp;t=0\\\\\\alpha Y_{t}+(1-\\alpha )\\cdot S_{t-1},&amp;t&gt;0\\end{cases}}} \\] <p>This can be seen as a weighted average between the previous output and the newest input sample. Alternatively this can be seen as the output moving a fractional amount towards to input for each sample. The result is a smoothed 1D signal, but introduces a delay in the signal. By applying the same filter twice in opposite directions, this delay is eliminated.</p> <p>Now, how can this be expanded to 3D? A three-dimensional orientation needs to be represented by at least three numbers, so one obvious way of filtering the orientation is to apply the low pass filter to each axis. Although this works, the result might not be the smoothing you expect. For instance, if the orientation is represented by an Euler angle, applying a low pass filter to each axis leads to non-linear behavior in the resulting orientation. If instead the orientations are represented by quaternions, the Slerp (Spherical Linear Interpolation, wiki article) method invented by Ken Shoemake can be used. Slerp can compute the intermediate orientation (quaternion) between two original quaternions corresponding to a smooth trajectory between the two. This is exactly what's needed for the simple exponential smoothing, since the weighted sum is equivalent to starting at \\(Y_{t}\\) and moving a fractional distance of \\(\\alpha\\) towards \\(S_{t-1}\\). This filter can thus be translated to an orientation filter as follows:</p> \\[ {\\displaystyle q_{out,t}={\\begin{cases}q_{in,t},&amp;t=0\\\\Slerp(q_{in,t}, q_{out,t-1},\\alpha) ,&amp;t&gt;0\\end{cases}}} \\] <p>Once again, this is applied in both directions to counteract the introduced delay. The difference between the input quaternions (estimated camera motion) and output quaternions (smoothed virtual camera) is then used for the image stabilization process. Due to the simplicity, this orientation filter was the first one implemented in the Gyroflow project, but has a number of limitations, mainly during large camera shakes and the lack of smoothness control for each rotational axis. Nevertheless, you should now have an overview of how the general smoothing algorithm works (Input orientation quaternions -&gt; Smoothing algo -&gt; Smoothed orientation quaternions) which might give you ideas for your own smoothing algorithm.</p>"}]}